{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMVQk8n2F4oE4mA4lVLyElM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wheemin-2/25-1-ESAA/blob/main/0505_HW_ML_DL_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **인공지능, 머신 러닝과 딥러닝**"
      ],
      "metadata": {
        "id": "iMgMwQYnEjuJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "인공지능(Artificial Intelligence , AI) : 인간의 지능을 모방하여 사람이 하는 일을 컴퓨터(기계)가 할 수 있도록 하는 기술\n",
        "\n",
        "인공지능을 구현하는 방법으로 머신 러닝(machine lea rning) 과 답러닝 (dcep learning) 이 있음\n",
        "\n",
        "![ai/dl/ml](https://thebook.io/img/080289/018.jpg)"
      ],
      "metadata": {
        "id": "nwYovYOgEtSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**머신러닝과 딥러닝의 차이**\n",
        "\n",
        "- 머신러닝과 딥러닝 모두 학습 모델을 제공하여 데이터를 분류할 수 있는 기술이지만, 접근 방식에 차이가 있음\n",
        "\n",
        "[머신 러닝]\n",
        "- 주어진 데이터를 인간이 먼저 처리(전처리)함\n",
        "- 이미지 데이터인 경우, 사람이 학습 데이터를 컴퓨터가 인식할 수 있도록 준비해야함\n",
        "\n",
        "[딥러닝]\n",
        "- 인간이 하던 작업 생략\n",
        "- 대량의 데이터를 신경망에 적용하면 컴퓨터가 스스로 분석한 후 답을 찾음\n",
        "\n",
        " ![ML/DL](https://thebook.io/img/080289/019.jpg)\n",
        "\n",
        "[동작원리]\n",
        "\n",
        "- 머신러닝 : 입력 데이터에 알고리즘을 적용해 예측 수행\n",
        "- 딥러닝 : 정보를 전달하는 신경망을 사용해 데이터 특징 및 관계 해석\n",
        "\n",
        "[재사용]\n",
        "\n",
        "- 머신러닝 : 입력 데이터 분석을 위해 다양한 알고리즘 사용 / 동일 유형의 데이터 분석을 위한 재사용은 불가\n",
        "- 딥러닝 : 구현된 알고리즙은 동일 유형의 데이터 분석 재사용이 가능\n",
        "\n",
        "[데이터]\n",
        "\n",
        "- 머신러닝 : 일반적으로 수천개 데이터 필요\n",
        "- 딥러닝 : 수백만개 이상의 데이터 필요\n",
        "\n",
        "[훈련 시간]\n",
        "\n",
        "- 머신러닝 : 단시간\n",
        "- 딥러닝 : 장시간\n",
        "\n",
        "[결과]\n",
        "\n",
        "- 머신러닝 : 점수 or 분류 등 숫자값\n",
        "- 딥러닝 : 점수/텍스트/소리 등 어떤 것이든 가능"
      ],
      "metadata": {
        "id": "04QufyHIFRcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **머신 러닝**"
      ],
      "metadata": {
        "id": "HAl8kQN0GrXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **머신 러닝 학습 과정**"
      ],
      "metadata": {
        "id": "KHvIMXcrGts0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신 러닝은 크게 학습 단계와 예측 단계로 구분할 수 있음\n",
        "\n",
        "훈련 데이터를 머신 러닝 알고리즘에 적용하여 \"학습\" > 이 학습 결과로 모형 생성 > 생성된 모형에 새로운 데이터를 적용하여 결과 \"예측\""
      ],
      "metadata": {
        "id": "Rm6mBHfbGv6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[머신 러닝의 주요 구성 요소]\n",
        "\n",
        "- 데이터 : 머신 러닝이 학습 모델을 만드는 데 사용하는 것\n",
        "    - 훈련 데이터가 나쁘면 실제 현상의 특성을 제대로 반영할 수 X\n",
        "    - 실제 데이터의 특징이 잘 반영되고 편향되지 않는 훈련 데이터를 확보하는 것이 중요\n",
        "- 모델 : 머신 러닝 학습 단계에서 얻은 최종 결과물, 가설이라고도 함\n",
        "    - 모델 선택 > 모델 학습 및 평가 > 평가를 바탕으로 모델 업데이트 : 이 과정을 반복하면서 최적의 모델을 찾음"
      ],
      "metadata": {
        "id": "Ixu3kAaWHIV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*훈련과 검증, 테스트 데이터셋*\n",
        "\n",
        "- 검증 데이터셋을 사용하는 이유? : 모델 성능을 평가 하기 위해서! 즉， 훈련 데이터셋으로 모델을 학습시킨 후 모델이 잘 예측하는지 그 성능을 평가하기 위해서 사용함\n",
        "    - 하지만 검증 용도의 데이터셋은 훈련 데이터셋의 일부를 떼어서 사용하기 때문에 학습에 사용되는 데이터 셋의 양이 많지 않다면 검증 데이터셋을 사용하는 것은 좋지 않음\n",
        "- 모델 성능 평가는 왜 필요할까? : 테스트 데이터셋에 대한 성능을 가늠해 볼 수 있고, 모델 성능을 높이는 데에 도움을 줌\n",
        "    - 훈련 데이터셋에 대한 정확도는 높은데, 검증 데이터셋에 대한 정확도가 낮다 > 과적합 가능성!! > 정규화(Regularization)/epoch 감소 등의 대처 가능"
      ],
      "metadata": {
        "id": "PmJry1a3Hpf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **머신 러닝 학습 알고리즘**"
      ],
      "metadata": {
        "id": "zUSoRs49IQqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신 러닝의 학습 알고리즘으로는 지도 학습, 비지도 학습, 강화 학습이 있음"
      ],
      "metadata": {
        "id": "CdKsfaNwITau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[지도 학습]\n",
        "- 정답이 무엇인지 알려주고 학습시키는 방법\n",
        "\n",
        "[비지도 학습]\n",
        "- 정답을 알려주지 않고 특징이 비슷한 테이터를 클러스터링하여 예측하는 학습 방법\n",
        "\n",
        "[강화 학습]\n",
        "- 분류할 수 있는 데이터 X, 정답 X\n",
        "- 자신의 행동에 대한 보상을 받으며 학습을 진행\n",
        "- 보상이 커지는 행동은 자주 하도록 하고, 줄어드는 행동은 덜 하도록 하여 학습을 진행함\n",
        "\n",
        "![ml algo](https://velog.velcdn.com/images/kwons/post/58fd10c5-d113-4ceb-b9ae-b27c068543a4/image.png)"
      ],
      "metadata": {
        "id": "qixxVL7sIdr6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **딥러닝**"
      ],
      "metadata": {
        "id": "Uqd3f8ugJI0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝은 인간의 신경망 원리를 모방한 심층 신경망 이론을 기반으로 고안된 머신 러닝 방법의 일종\n",
        "> 컴퓨터에 뉴런과 시냅스 개념을 적용함, 각각의 뉴런은 복잡하게 연결된 수많은 뉴런을 병렬 연산하여 기존에 컴퓨터가 수행하지 못했던 음성/영상 인식 등의 처리를 가능하게 함\n",
        "\n",
        "![NN](https://velog.velcdn.com/images/kwons/post/fe2f6d47-88e3-43b0-9ef0-af074f4f04c4/image.png)"
      ],
      "metadata": {
        "id": "CKF-hmAAJLZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **딥러닝 학습 과정**"
      ],
      "metadata": {
        "id": "By_vOxA-JwQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![DL algo](https://velog.velcdn.com/images/kwons/post/0218b637-2a55-45ee-bf60-6b04ecc30bbe/image.png)\n",
        "\n",
        "\n",
        "[모델 정의]\n",
        "- 신경망을 생성하는 단계\n",
        "- 일반적으로 은닉층 개수가 많을수록 성능이 좋아지지만 과적합이 발생할 확률이 높아짐 (은닉층 개수에 따른 성능과 과적합은 서로 상충관계)\n",
        "\n",
        "[모델 컴파일]\n",
        "- 활성화 함수, 손실 함수, 옵티마이저 선택\n",
        "    - 활성화 함수 : 입력 신호가 일정 기준 이상이면 출력 신호로 변환하는 함수 (Sigmoid, ReLu 등)\n",
        "    - 옵티마이저 : 손실 함수를 기반으로 네트워크 업데이트 방법을 결정 (Adam, RMSProp 등)\n",
        "- 과적합을 피할 수 있는 활성화 함수/옵티마이저 선택이 중요함\n",
        "\n",
        "[모델 훈련]\n",
        "- 한 번에 처리할 데이터양을 지정\n",
        "    - 데이터양 ↑ : 학습 속도 ↓, 메모리 부족 문제 발생 가능\n",
        "    - 적절하게 설정해야 함\n",
        "- batch, epoch 선택이 중요\n",
        "    - batch : 전체 훈련 데이터셋에서 일정 한 묶음으로 나누어 처리할 수 있는 것\n",
        "    - epoch : 훈련 횟수\n",
        "    ![batch/epoch](https://thebook.io/img/080289/027.jpg)\n",
        "\n",
        "[모델 예측]\n",
        "- 검증 데이터셋을 모델에 적용하여 실제로 예측을 진행하는 단계\n",
        "- 이때 성능이 낮다면 파라미터 튜닝/신경망 재설계 진행"
      ],
      "metadata": {
        "id": "-rOgpb9VJ0Sp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**batch_size와 epoch**\n",
        "\n",
        "💡 Epoch란?\n",
        "\n",
        "> 인공 신경망에서 전체 데이터에 대해서 순전파와 역전파가 끝난 상태\n",
        "\n",
        "> ex) 전체 데이터를 하나의 문제지에 비유한다면 문제지의 모든 문제를 끝까지 다 풀고, 정답지로 채점을 하여 문제지에 대한 공부를 한 번 끝낸 상태\n",
        "\n",
        "💡 Batch_size란?\n",
        "\n",
        "> 몇 개의 데이터 단위로 매개변수를 업데이트 하는지를 말함.\n",
        "\n",
        "> ex) 문제지에서 몇 개씩 문제를 풀고나서 정답지를 확인하느냐의 문제. 기계 입장에서는 실제값과 예측값으로부터 오차를 계산하고 옵티마이저가 매개변수를 업데이트함.\n",
        "\n",
        "여기서 중요한 포인트는 **업데이트가 시작되는 시점 = 정답지/실제값을 확인하는 시점**\n",
        "\n",
        "💡 훈련 데이터셋 1000개에 대한 에포크가 10이고, 배치 크기가 20인 경우\n",
        "\n",
        "- batch_size=20 : 샘플 단위 20개마다 모델 가중치를 한 번씩 업데이트 >> 총 50번 가중치가 업데이트 됨\n",
        "- epoch=10 : 가중치 50번 업데이트하는 것을 총 10번 반복\n",
        "- 결과적으로 가중치는 총 500번 업데이트 됨"
      ],
      "metadata": {
        "id": "Hz2oKKbdL2E6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**신경망과 역전파**\n",
        "\n",
        "딥러닝 학습 과정에서 중요한 핵심 구성 요소 : 신경망과 역전파\n",
        "\n",
        "- 딥러닝은 머신 러닝의 한 분야이지만, 심층 신경망(deep neural network)을 사용한다는 점에서 머신 러닝과 차이가 있음\n",
        " - 심층 신경망 : 은닉층이 두 개 이상인 신경망, 데이터셋의 어떤 특성들이 중요한지 스스로에게 가르쳐 줄 수 있는 기능이 있음\n",
        " ![deep nn](https://velog.velcdn.com/images/kwons/post/1da6ca2e-0377-4134-be8f-3795e084575d/image.png)\n",
        "\n",
        "- 역전파 : 가중치 값을 업데이트하는 역할\n",
        "    - 역전파 계산 과정에서 사용되는 미분(오차를 각 가중치로 미분)이 성능에 영향을 미치는 주요한 요소!\n",
        "    - 파이토치와 같은 프레임워크는 역전파 알고리즘을 자동으로 처리해주므로 딥러닝 알고리즘 구현이 간단하고 편리해짐\n",
        "    ![BackPropagation](https://velog.velcdn.com/images/kwons/post/90d6ef29-9058-4afd-9627-213bbd2c385b/image.png)"
      ],
      "metadata": {
        "id": "wmfxCEFITtxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **딥러닝 학습 알고리즘**"
      ],
      "metadata": {
        "id": "-IPds54DUt6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "활용 분야에 따라 지도학습, 비지도 학습, 전이 학습으로 분류됨\n",
        "\n",
        "![DL algo2](https://velog.velcdn.com/images/kwons/post/79e42c9b-b79f-45af-be3d-c92bc198bd38/image.png)\n",
        "\n",
        "[지도 학습]\n",
        "- 이미지 분류\n",
        "    - 이미지 or 비디오상의 객체를 식별하는 컴퓨터 비전 기술\n",
        "    - 목적에 따라 이미지분류/이미지인식/이미지분할로 나뉨\n",
        "\n",
        "    ex) CNN : 합성곱 신경망\n",
        "\n",
        "- 시계열 데이터 분석\n",
        "    - RNN (순환신경망) : 시간에 따른 데이터에 사용, but 역전파 과정에서 **기울기 소멸 문제** 발생\n",
        "    - LSTM : RNN의 문제점을 개선하고자 게이트(gate) 3개 추가\n",
        "        - 망각게이트/입력게이트/출력게이트를 도입하여 기울기 소멸 문제 해결\n",
        "        - 현재 시계열 문제에서 가장 활발히 사용 중\n",
        "\n",
        "[비지도 학습]\n",
        "- 워드 임베딩\n",
        "    - 단어를 벡터로 변환하여 컴퓨터가 이해할 수 있도록 함\n",
        "    - NLP 분야의 일종으로, 번역/음성 인식 등의 서비스에서 사용함\n",
        "    - Word2Vec, GloVe를 가장 많이 사용\n",
        "- 군집\n",
        "    - 아무런 정보가 없는 상태에서 데이터를 분류하는 방법\n",
        "    - 군집 간은 구분이 되도록, 군집 내 요소들은 비슷하게 구성하는 것이 목표\n",
        "    - 머신 러닝의 군집과 크게 다르지 않으나, 머신 러닝에서 군집화를 처리할 때 딥러닝과 함께 사용하면 모델 성능을 높일 수 있음\n",
        "\n",
        "[전이 학습]\n",
        "- 사전 학습 모델을 이용하여 미세조정기법을 통해 학습시키는 방법\n",
        "    - 사전 학습 모델 : 풀고자 하는 문제와 비슷하면서 많은 데이터로 이미 학습되어있는 모델\n",
        "\n",
        "    ex) VGG, 인셉션, MobileNet"
      ],
      "metadata": {
        "id": "2wBHnoDdUwQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **파이토치**"
      ],
      "metadata": {
        "id": "q1aiM_PTXbji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **파이토치 특징 및 장점**\n",
        "\n",
        "> **\"GPU에서 텐서 조작 및 동적 신경망 구축이 가능한 프레임워크\"**"
      ],
      "metadata": {
        "id": "nN3xUsswXc9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPU (Graphics Processing Unit)** : 연산 속도를 빠르게 하는 역할\n",
        "- 딥러닝에서는 기울기를 계산할 때 미분을 사용, GPU 사용 시 빠른 계산이 가능\n",
        "- 병렬 연산에서의 속도 : GPU >> CPU\n",
        "- 딥러닝 학습에서 GPU 사용은 필수적\n",
        "\n",
        "**텐서(Tensor)**\n",
        "- pytorch의 데이터 형태\n",
        "- 단일 데이터 형식으로 된 자료들의 다차원 행렬\n",
        "- 간단한 명령어를 사용해 GPU로 연산을 수행하게 할 수 있음\n",
        "\n",
        "**동적 신경망** : 훈련을 반복할 때마다 네트워크 변경이 가능한 신경망 (ex. 학습 중에 은닉층 추가/제거 등 조작이 가능)\n",
        "\n",
        "- 'Define by Run' 방식 사용 : 연산 그래프를 정의하는 것과 동시에 값도 초기화 됨\n",
        "- 연산 그래프와 연산을 분리해서 생각할 필요가 없으므로 코드 이해가 쉬움\n",
        " ![define by run](https://velog.velcdn.com/images/kwons/post/8eaecb7f-1aef-4929-a8e2-dfe1ac2dea65/image.png)"
      ],
      "metadata": {
        "id": "gsIM5uYgYvVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**벡터, 행렬, 텐서**\n",
        "\n",
        "![vector, matrix, tensor](https://thebook.io/img/080289/035_2.jpg)\n",
        "\n",
        "- 벡터 : 1차원 배열 형태\n",
        "- 행렬 : 2차원 배열 형태\n",
        "- 텐서 : 3차원 이상의 배열 형태\n",
        "- axis 0 : 1차원 축(행), 벡터 / axis 1 : 2차원 축(열), 행렬 / axis 2 : 3차원 축(채널), 텐서"
      ],
      "metadata": {
        "id": "7Gd6nHI6aK8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **파이토치의 아키텍처**"
      ],
      "metadata": {
        "id": "VVO4J7FGbI_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치 아키텍처는 세 개의 계층으로 나누어볼 수 있음\n",
        "\n",
        "![pytorch arch](https://velog.velcdn.com/images/kwons/post/12e60fd2-de28-4d15-9ce5-c5dcf8fbb95e/image.png)"
      ],
      "metadata": {
        "id": "QK3ZpICWbOu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **파이토치 API**"
      ],
      "metadata": {
        "id": "tGwGyrl7lMXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치 API 계층에서는 사용자가 이해하기 쉬운 API를 제공하여 텐서에 대한 처리와 신경망을 구축하고 훈련할 수 있도록 도움. 이 계층에서는 사용자 인터페이스를 제공하지만 실제 계산은 수행하지 않고, C++로 작성된 파이토치 엔진으로 그 작업을 전달하는 역할만 함"
      ],
      "metadata": {
        "id": "Wmz5cH6YlO31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[파이토치 API 계층에서 제공하는 패키지]\n",
        "- `torch` : GPU 지원 텐서 패키지\n",
        "    - 다차원 텐서를 기반으로 다양한 수학적 연산이 가능하도록 함\n",
        "- `torch.autograd` : 자동 미분 패키지\n",
        "    - 연산 그래프가 즉시 계산(실시간으로 네트워크 수정이 반영된 계산)되기 때문에 사용자는 다양한 신경망을 적용해볼 수 있음\n",
        "    \n",
        "   *일반적으로 신경망에 사소한 변경이 있다면 신경망 구축을 처음부터 다시 시작해야함\n",
        "\n",
        "- `torch.nn` : 신경망 구축 및 훈련 패키지\n",
        "- `torch.multiprocessing` : 파이썬 멀티프로세싱 패키지\n",
        "- `torch.utils` : DataLoader 및 기타 유틸리티 제공"
      ],
      "metadata": {
        "id": "hLlFMP4Ulc9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **파이토치 기초 문법**"
      ],
      "metadata": {
        "id": "NokfmIoam-yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **텐서 다루기**"
      ],
      "metadata": {
        "id": "jLNJEAf-nBYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **텐서 생성 및 변환**"
      ],
      "metadata": {
        "id": "TjVa0jL5nK1J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUx3Miu2Dk_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a4cc4a-af3d-4fd1-d61d-271a8462fc37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.tensor([[1,2], [3,4]])) # 2차원 형태의 텐서\n",
        "#print(torch.tensor([[1,2], [3,4]], device='cuda:0')) # GPU에 텐서 생성\n",
        "print(torch.tensor([[1,2], [3,4]], dtype=torch.float64))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서를 ndarray로 변환\n",
        "temp = torch.tensor([[1,2],[3,4]])\n",
        "print(temp.numpy())\n",
        "\n",
        "#print(torch.tensor([[1,2], [3,4]], device='cuda:0'))\n",
        "#print(temp.to('cpu').numpy()) # GPU상의 텐서를 CPU의 텐서로 변환 후 ndarrary로 변환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGzm2eAATtjQ",
        "outputId": "995587f0-641c-4a17-af4b-6b5a66155b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **텐서의 인덱스 조작**"
      ],
      "metadata": {
        "id": "nabVmsL4YR9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서는 넘파이의 ndarray를 조작하는 것과 유사하게 동작함\n",
        "> 배열처럼 인덱스를 바로 지정하거나, 슬라이스 등을 사용할 수 있음\n",
        "\n",
        "[텐서의 자료형]\n",
        "- `torch.FloatTensor` : 32비트의 부동 소수점\n",
        "- `torch.DoubleTensor` : 64비트의 부동 소수점\n",
        "- `torch.LongTensor` : 64비트의 부호가 있는 정수\n",
        "- 그 외"
      ],
      "metadata": {
        "id": "aCeTecf7Yjek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.FloatTensor([1,2,3,4,5,6,7]) # 1차원 벡터 생성\n",
        "print(temp[0], temp[1], temp[-1]) # 인덱스로 접근\n",
        "print('---------------')\n",
        "print(temp[2:5], temp[4:-1]) # 슬라이스로 접근"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE7yjpGfYQuB",
        "outputId": "d0b9999a-2d8f-43a2-de15-0d1c41d5b4b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.) tensor(2.) tensor(7.)\n",
            "---------------\n",
            "tensor([3., 4., 5.]) tensor([5., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **텐서 연산 및 차원 조작**"
      ],
      "metadata": {
        "id": "9KJJB7CmZMF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[텐서의 연산]\n",
        "\n",
        "텐서는 넘파이의 ndarray처럼 다양한 수학 연산이 가능, GPU를 사용하면 더 빠르게 연산할 수 있음\n",
        "\n",
        "**텐서 간의 타입이 다르면 연산이 불가능 !! (ex. FloatTensor와 DoubleTensor 간의 연산 불가능)*"
      ],
      "metadata": {
        "id": "BLJTOUGvZPrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.tensor([1,2,3])\n",
        "w = torch.tensor([3,4,6])\n",
        "print(w - v)  # elementwise 계산"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE0XtVRXZHnY",
        "outputId": "6807da4c-af87-4dfd-b737-278c564c1767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[텐서의 차원 조작]\n",
        "- `view` : 텐서의 차원을 변경하는 가장 대표적인 방법 (np.reshape과 유사)\n",
        "- `stack`, `cat` : 텐서를 결합\n",
        "- `t`, `transpose` : 텐서의 차원을 교환"
      ],
      "metadata": {
        "id": "dpX6_NPQZq6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[1,2], [3,4]])  # 2x2 mtx\n",
        "\n",
        "print(temp.shape)\n",
        "print('-------------------')\n",
        "print(temp.view(4,1))  # 4x1로 차원 변경\n",
        "print('-------------------')\n",
        "print(temp.view(-1)) # 1차원 벡터로 변경\n",
        "print('-------------------')\n",
        "print(temp.view(1,-1))\n",
        "print('-------------------')\n",
        "print(temp.view(-1,1)) # 2차원 (4,1) 행렬"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_smQo86KZk80",
        "outputId": "918e5a16-6380-4846-a59b-02fcbd15ff9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "-------------------\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n",
            "-------------------\n",
            "tensor([1, 2, 3, 4])\n",
            "-------------------\n",
            "tensor([[1, 2, 3, 4]])\n",
            "-------------------\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **데이터 준비**"
      ],
      "metadata": {
        "id": "XMhNODVfaclb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[파일을 불러와서 사용]\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import pandas as pd ------ pandas 라이브러리 호출\n",
        "import torch ------ torch 라이브러리 호출\n",
        "data = pd.read_csv('../class2.csv') ------ csv 파일을 불러옵니다.\n",
        "\n",
        "x = torch.from_numpy(data['x'].values).unsqueeze(dim=1).float() ------ CSV 파일의 x 칼럼의 값을 넘파이 배열로 받아 Tensor(dtype)으로 바꾸어 줍니다.\n",
        "y = torch.from_numpy(data['y'].values).unsqueeze(dim=1).float() ------ CSV 파일의 y 칼럼의 값을 넘파이 배열로 받아 Tensor(dtype)으로 바꾸어 줍니다.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vfMVsovEbZ4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[커스텀 데이터셋을 만들어서 사용]\n",
        "\n",
        "커스텀 데이터셋(custom dataset)\n",
        "- 데이터를 한 번에 다 부르지 않고 조금씩 나누어 불러서 사용하는 방식\n",
        "- 딥러닝은 기본적으로 대량의 데이터를 이용하여 모델을 학습시키는데, 데이터를 한 번에 불러와서 훈련시키면 시간과 비용 측면에서 효율적이지 않음\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# 기본 구조\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init __(self): ------ 필요한 변수를 선언하고, 데이터셋의 전처리를 해 주는 함수\n",
        "    def __len __(self): ------ 데이터셋의 길이. 즉, 총 샘플의 수를 가져오는 함수\n",
        "    def __getitem __(self, index): ------ 데이터셋에서 특정 데이터를 가져오는 함수\n",
        "                                (index번째 데이터를 반환하는 함수이며, 이때 반환되는 값은 텐서의 형태를 취해야 합니다)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "bTiWh4ycbkjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "8rkgmsg9aSlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file):   # 데이터 불러오기\n",
        "        self.label = pd.read_csv(csv_file)\n",
        "\n",
        "    def __len__(self):     # 데이터셋의 크기 반환\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):    # 특정 데이터를 반환(idx 번째의 데이터 반환)\n",
        "        sample = torch.tensor(self.label.iloc[idx,0:3]).int()\n",
        "        label = torch.tensor(self.label.iloc[idx,3]).int()\n",
        "        return sample, label\n",
        "\n",
        "#tensor_dataset = CustomDataset('../covtype.csv')\n",
        "#dataset = DataLoader(tensor_dataset, batch_size=4, shuffle=True)   # 원하는 만큼만 가져"
      ],
      "metadata": {
        "id": "PMweAExLcSOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**torch.utils.data.DataLoader**\n",
        "\n",
        "- 데이터로더(DataLoader) 객체는 학습에 사용될 데이터 전체를 보관했다가 모델 학습을 할 때 배치 크기만큼 데이터를 꺼내서 사용\n",
        "- 데이터를 미리 잘라 놓는 것이 아니라 내부적으로 반복자(iterator)에 포함된 인덱스(index)를 이용하여 배치 크기만큼 데이터를 반환함!!\n",
        "\n",
        "![dataloader](https://thebook.io/img/080289/048.jpg)\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# 다음과 같이 작동함\n",
        "for i, data in enumerate(dataset,0):\n",
        "    print(i, end='')\n",
        "    batch=data[0]\n",
        "    print(batch.size())\n",
        "\n",
        "# 출력 결과\n",
        "0torch.Size([4, 3])\n",
        "1torch.Size([4, 3])\n",
        "2torch.Size([4, 3])\n",
        "3torch.Size([4, 3])\n",
        "4torch.Size([3, 3])\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nW4VK_pEdxkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[파이토치에서 제공하는 데이터셋 사용]"
      ],
      "metadata": {
        "id": "zABBgy6QeoyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "토치비전(torchvision) : 파이토치에서 제공하는 데이터셋이 모여 있는 패키지\n",
        "- MNIST, ImageNet을 포함한 유명 데이터셋을 제공"
      ],
      "metadata": {
        "id": "GAWnpN0OexQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치에서 제공하는 데이터셋을 내려받으려면 requests 라이브러리 설치 필요\n",
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNdzkQRqdFS3",
        "outputId": "65a519fc-6ce3-4a16-b25f-863c28a940f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 데이터 내려받기\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "mnist_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5,), (1.0))]) # 평균이 0.5, sd가 1이 되도록 데이터 분포 조정\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "import requests\n",
        "\n",
        "download_root = '../chap02/data/MNIST_DATASET' # 내려받을 경로 지정\n",
        "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
        "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
        "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JfX6JXnfA6u",
        "outputId": "ee3fbbb1-193c-4d77-f93f-99f271da7ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 489kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.54MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.06MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 정의**"
      ],
      "metadata": {
        "id": "fiFQHxcNgFrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치에서 모델을 정의하기 위해서는 모듈을 상속한 클래스를 사용\n",
        "\n",
        "- 계층(layer) : 모듈 또는 모듈을 구성하는 한 개의 계층으로, 합성곱층(convolutional layer), 선형 계층(linear layer) 등이 있음\n",
        "- 모듈(module) : 한 개 이상의 계층이 모여서 구성된 것, 모듈이 모여 새로운 모듈을 만드는 것도 가능\n",
        "- 모델(model) : 최종적으로 원하는 네트워크, 한 개의 모듈이 모델이 될 수도 있음"
      ],
      "metadata": {
        "id": "TQ3ZIYs0gIQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **단순 신경망 정의**"
      ],
      "metadata": {
        "id": "vD3NTJjVgi9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Module을 상속받지 않는 매우 단순한 모델을 만들 때 사용, 구현이 쉽고 단순함\n",
        "\n",
        "```\n",
        "model = nn.Linear(in_features=1, out_features=1, bias=True)\n",
        "```"
      ],
      "metadata": {
        "id": "YrsMUQCLgmi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **nn.Module()을 상속하여 정의**"
      ],
      "metadata": {
        "id": "bHWoAy-dgvZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치에서 nn.Module을 상속받는 모델은 기본적으로 __init__()과 forward() 함수를 포함\n",
        "- __init__() : 모델에서 사용될 모듈(nn.Linear, nn.Conv2d), 활성화 함수 등을 정의\n",
        "- forward() : 모델에서 실행되어야 하는 연산을 정의"
      ],
      "metadata": {
        "id": "TPB9cNO5g8m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module, Linear, Sigmoid\n",
        "\n",
        "class MLP(Module):\n",
        "    def __init__(self, inputs):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer = Linear(inputs, 1)  # 계층 정의\n",
        "        self.activation = Sigmoid()   # 활성화 함수 정의\n",
        "    def forward(self, X):\n",
        "        X = self.layer(X)\n",
        "        X = self.activation(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "bmYm_8bef58l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sequential 신경망 정의**"
      ],
      "metadata": {
        "id": "e30XF3XgmZc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`nn.Sequential`을 사용하면 __init__()에서 사용할 네트워크 모델들을 정의해 줄 뿐만 아니라 forward() 함수에서는 모델에서 실행되어야 할 계산을 좀 더 가독성이 뛰어나게 코드로 작성할 수 있음.\n",
        "\n",
        "- Sequential 객체는 그 안에 포함된 각 모듈을 순차적으로 실행함\n",
        "- 모델의 계층이 복잡할 수록 효과가 뛰어남"
      ],
      "metadata": {
        "id": "WEOHW6ZBmf08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=30, kernel_size=5),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.layer1(x)\n",
        "            x = self.layer2(x)\n",
        "            x = x.view(x.shape[0],-1)\n",
        "            x = self.layer3(x)\n",
        "            return x\n",
        "\n",
        "model = MLP()  # 모델에 대한 객체 생성\n",
        "\n",
        "print('Printing childern\\n---------------------')\n",
        "print(list(model.children()))\n",
        "print('\\n\\nPrinting Modules\\n---------------------')\n",
        "print(list(model.modules()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk-fzky_ha8m",
        "outputId": "aee9e0e4-2e56-4e5b-e9eb-e877b183ef18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing childern\n",
            "---------------------\n",
            "[Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Sequential(\n",
            "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            ")]\n",
            "\n",
            "\n",
            "Printing Modules\n",
            "---------------------\n",
            "[MLP(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Linear(in_features=750, out_features=10, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "), Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
            "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
            "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "), Linear(in_features=750, out_features=10, bias=True), ReLU(inplace=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model.modules() & model.children()**\n",
        "\n",
        "`model.modules()` : 모델 네트워크에 대한 모든 노드를 반환\n",
        "\n",
        "`model.childern()` : 같은 수준(level)의 하위 노드를 반환\n",
        "\n",
        "![module/children](https://thebook.io/img/080289/053.jpg)"
      ],
      "metadata": {
        "id": "BePojzeloC7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **함수로 신경망 정의**\n"
      ],
      "metadata": {
        "id": "Wy_K9WjNoXdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 장점 : Sequential을 사용하는 것과 동일하지만, 함수로 선언할 경우 변수에 저장해 놓은 계층들을 재사용할 수 있음\n",
        "- 단점 : 모델이 복잡해짐 (복잡한 모델의 경우, 함수를 이용하는 것보다는 nn.Module()을 상속받아 사용하는 것이 편리)\n",
        "- ReLU, Softmax, Sigmoid와 같은 활성화 함수는 모델을 정의할 때 지정"
      ],
      "metadata": {
        "id": "OBr38aT5ob1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
        "    hidden = nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)\n",
        "    activation = nn.ReLU()\n",
        "    output = nn.Linear(in_features=hidden_features, out_features=out_features, bias=True)\n",
        "    net = nn.Sequential(hidden, activation, output)\n",
        "    return net"
      ],
      "metadata": {
        "id": "Tg8ZJmhHntUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 파라미터 정의**"
      ],
      "metadata": {
        "id": "VElb38TJpdwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[사전에 정의할 파라미터 목록]\n",
        "\n",
        "★**손실 함수(loss function)** : 학습하는 동안 출력과 실제 값(정답) 사이의 오차를 측정함. 즉, wx + b를 계산한 값과 실제 값인 y의 오차를 구해서 모델의 정확성을 측정\n",
        "    \n",
        "- 자주 사용하는 loss function\n",
        "\n",
        "    • BCELoss: 이진 분류를 위해 사용\n",
        "\n",
        "    • CrossEntropyLoss: 다중 클래스 분류를 위해 사용\n",
        "\n",
        "    • MSELoss: 회귀 모델에서 사용\n",
        "\n",
        "★**옵티마이저(optimizer)** : 데이터와 손실 함수를 바탕으로 모델의 업데이트 방법을 결정\n",
        "- optimizer의 주요 특성\n",
        "\n",
        "    • step() 메서드를 통해 전달받은 파라미터를 업데이트함\n",
        "\n",
        "    • 모델의 파라미터별로 다른 기준(ex. 학습률) 적용 가능\n",
        "\n",
        "    • `torch.optim.Optimizer(params, defaults)` : 모든 옵티마이저의 기본이 되는 클래스\n",
        "\n",
        "    • `zero_grad()` : 옵티마이저에 사용된 파라미터들의 기울기(gradient)를 0으로 만들어줌\n",
        "\n",
        "    • `torch.optim.lr_scheduler` : 에포크에 따라 학습률 조절 가능\n",
        "\n",
        "- optimizer 종류\n",
        "\n",
        "    • optim.Adadelta, optim.Adagrad, optim.Adam, optim.SparseAdam, optim.Adamax\n",
        "\n",
        "    • optim.ASGD, optim.LBFGS\n",
        "\n",
        "    • optim.RMSProp, optim.Rprop, optim.SGD\n",
        "\n",
        "★**학습률 스케줄러(learning rate scheduler)** : 미리 지정한 횟수의 에포크를 지날 때마다 학습률을 감소(decay)시킴. 학습률 스케줄러를 이용하면 학습 초기에는 빠른 학습을 진행하다가 전역 최소점(global minimum) 근처에 다다르면 학습률을 줄여서 최적점을 찾아갈 수 있도록 함.\n",
        "- 학습률 스케줄러의 종류\n",
        "\n",
        "    • `optim.lr_scheduler.LambdaLR` : 람다(lambda) 함수를 이용하여 그 함수의 결과를 학습률로 설정\n",
        "\n",
        "    • `optim.lr_scheduler.StepLR` : 특정 단계(step)마다 학습률을 감마(gamma) 비율만큼 감소시킴\n",
        "\n",
        "    • `optim.lr_scheduler.MultiStepLR` : StepLR과 비슷하지만 특정 단계가 아닌 지정된 에포크에만 감마 비율로 감소시킴\n",
        "\n",
        "    • `optim.lr_scheduler.ExponentialLR` : 에포크마다 이전 학습률에 감마만큼 곱함\n",
        "\n",
        "    • `optim.lr_scheduler.CosineAnnealingLR` : 학습률을 코사인(cosine) 함수의 형태처럼 변화시킴 > 학습률이 커지기도, 작아지기도 함\n",
        "\n",
        "    • `optim.lr_scheduler.ReduceLROnPlateau` : 학습이 잘되고 있는지 아닌지에 따라 동적으로 학습률을 변화시킬 수 있음\n",
        "\n",
        "★**지표(metrics)**: 훈련과 테스트 단계를 모니터링"
      ],
      "metadata": {
        "id": "WNkOuxhapgpL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 모델 파라미터를 정의하는 예시 코드\n",
        "from torch.optim import optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.pareameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.LamdaLR(optimizer=optimizer, lr_lambda=lambda epoch: 0.95**epoch)\n",
        "\n",
        "for epoch in range(1, 100+1):   # epoch 수만큼 데이터를 반복하여 처리\n",
        "    for x, y in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "loss_fn(model(x), y).backward()\n",
        "optimizer.step()\n",
        "scheduler.step()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "gKpi-aWSsbes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 훈련**"
      ],
      "metadata": {
        "id": "LmCFksVbsf9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 학습시킨다 : $y = wx + b$ 함수에서 적절한 $w$와 $b$의 값을 찾는다!\n",
        "- $w$와 $b$에 임의의 값을 적용하여 시작, 오차가 줄어들어 적역 최소점에 이를 때까지 파라미터$(w,b)$를 계속 수정\n",
        "\n",
        "[모델 훈련 방법]\n",
        "\n",
        "Step 1. `optimizer.zero_grad()` 메서드를 이용하여 기울기 초기화\n",
        "- `loss.backward()` 메서드 : 새로운 기울기 값이 이전 기울기 값에 누적하여 계산됨\n",
        "- 이는 RNN 모델을 구현할 때는 효과적이지만, 누적 계산이 필요하지 않은 모델에 대해서는 불필요함\n",
        "- 따라서 기울기 값에 대해 누적 계산이 필요하지 않을 때는 입력값을 모델에 적용하기 전 `optimizer.zero_grad()` 메서드를 호출하여 미분 값을 초기화해 주어야 함\n",
        "\n",
        "Step 2. `loss.backward()` 메서드를 이용하여 기울기를 자동 계산\n",
        "- `loss.backward()` : 배치가 반복될 때마다 오차가 중첩적으로 쌓이게 되므로 미분값 초기화 필요!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# 모델 훈련 예시 코드\n",
        "\n",
        "for epoch in range(100):\n",
        "    yhat = model(x_train)\n",
        "    loss = criterion(yhat, y_train)\n",
        "    optimizer.zero_grad()  \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "```\n",
        "\n",
        "![training steps](https://thebook.io/img/080289/057.jpg)\n",
        "\n"
      ],
      "metadata": {
        "id": "cwl8P4ksw1AC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 평가**"
      ],
      "metadata": {
        "id": "p7pvIxElyNzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "XutJ_OaqshAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476f3264-52d9-4f44-fef4-6b94903128de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수를 이용한 모델 평가 코드\n",
        "import torch\n",
        "import torchmetrics\n",
        "\n",
        "preds = torch.randn(10, 5).softmax(dim=-1)\n",
        "target = torch.randint(5, (10,))\n",
        "\n",
        "acc = torchmetrics.functional.accuracy(preds, target, task=\"multiclass\", num_classes=5)"
      ],
      "metadata": {
        "id": "Zd9p2tXLyRpj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MqJTlr2y_v5",
        "outputId": "ff7881df-ab0d-43a3-9ab7-a189e9421e17"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3000)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모듈을 이용한 모델 평가 코드\n",
        "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=5)   # 모델 평가(정확도) 초기화\n",
        "\n",
        "n_batches = 10\n",
        "for i in range(n_batches):\n",
        "    preds = torch.randn(10, 5).softmax(dim=-1)\n",
        "    target = torch.randint(5, (10,))\n",
        "\n",
        "    acc = metric(preds, target)\n",
        "    print(f\"Accuracy on batch {i}: {acc}\")   # 현재 배치에서 모델 평가\n",
        "\n",
        "acc = metric.compute()\n",
        "print(f'Accuracy on all data: {acc}')   # 모든 배치에서 모델 평가"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WSvkKSqyf65",
        "outputId": "5899eb4c-ccf4-4e47-a12c-97e574c40bf5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on batch 0: 0.30000001192092896\n",
            "Accuracy on batch 1: 0.10000000149011612\n",
            "Accuracy on batch 2: 0.10000000149011612\n",
            "Accuracy on batch 3: 0.10000000149011612\n",
            "Accuracy on batch 4: 0.10000000149011612\n",
            "Accuracy on batch 5: 0.30000001192092896\n",
            "Accuracy on batch 6: 0.0\n",
            "Accuracy on batch 7: 0.20000000298023224\n",
            "Accuracy on batch 8: 0.10000000149011612\n",
            "Accuracy on batch 9: 0.4000000059604645\n",
            "Accuracy on all data: 0.17000000178813934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **훈련 과정 모니터링**"
      ],
      "metadata": {
        "id": "EoOPjOSVzY9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치로 머신러닝/딥러닝 모델을 만들어 학습해보면 학습이 진행되는 과정에서 각 파라미터에 어떤 값들이 어떻게 변화하는지 모니터링하기 어려움\n",
        "> **텐서보드**를 이용하면 학습에 사용되는 각종 파라미터 값이 어떻게 변화하는지 손쉽게 시각화하여 살펴볼 수 있음 + 성능을 추적, 평가하는 용도로도 사용 가능"
      ],
      "metadata": {
        "id": "kUojK0v9zcn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "!pip install tensorboard\n",
        "```\n",
        "\n",
        "```\n",
        "# 텐서보드 사용 코드\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter(\"../chap02/tensorboard\") ------ 모니터링에 필요한 값들이 저장될 위치\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train() ------ 학습 모드로 전환(dropout=True)\n",
        "    batch_loss = 0.0\n",
        "\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device).float(), y.to(device).float()\n",
        "        outputs = model(x)\n",
        "        loss = criterion(outputs, y)\n",
        "        writer.add_scalar(\"Loss\", loss, epoch) ------ 스칼라 값(오차)을 기록\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "writer.close() ------ SummaryWriter가 더 이상 필요하지 않으면 close( ) 메서드 호출\n",
        "```\n",
        "```\n",
        "tensorboard --logdir=../chap02/tensorboard --port=6006\n",
        "# 웹 브라우저에서 http://localhost:6006 입력 시 텐서보드 페이지가 열림\n",
        "```\n",
        "\n",
        "![tensorboard](https://thebook.io/img/080289/060.jpg)\n"
      ],
      "metadata": {
        "id": "8krxX80h0P4p"
      }
    }
  ]
}