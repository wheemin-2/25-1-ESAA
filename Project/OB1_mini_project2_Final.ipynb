{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wheemin-2/25-1-ESAA/blob/main/OB1_mini_project2_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqb5AJRey09Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328390cf-7ef1-413f-aae3-10e788ce7d00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import nltk"
      ],
      "metadata": {
        "id": "ZIIvoulH8EFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 로드\n",
        "- `train.csv`, `test_x.csv` 불러오기"
      ],
      "metadata": {
        "id": "8uW2kYj0qSsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ESAA/25-1 OB/mini project 2/train.csv\", encoding='utf-8')\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ESAA/25-1 OB/mini project 2/test_x.csv\", encoding='utf-8')"
      ],
      "metadata": {
        "id": "p3gVHNfk7Jb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBO8cHpzRvV3",
        "outputId": "2899f01f-d351-430d-c63b-b005f2a3cc6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "56_pxLgkcDXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3FRs3fUcm3G",
        "outputId": "acefe12b-b6ce-4cb7-8dd2-4a1c50aeaa65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['index', 'text', 'author'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train['author'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lSaudDZJ30n",
        "outputId": "d9f700c3-4dd3-47df-9c6c-7da6dffdb902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 2 1 4 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 피처 생성\n",
        "\n",
        "1. **`num_words`**  \n",
        "   - 텍스트를 공백(`\" \"`) 기준으로 분할한 뒤, 전체 단어의 개수를 계산  \n",
        "\n",
        "2. **`num_unique_words`**  \n",
        "   - 텍스트 내 중복을 제거한 뒤 고유 단어의 개수를 계산  \n",
        "\n",
        "3. **`num_chars`**  \n",
        "   - 텍스트 문자열 전체 길이(문자 수)를 계산\n",
        "\n",
        "4. **`num_punctuations`**  \n",
        "   - `string.punctuation`에 정의된 모든 구두점 문자를 찾아 개수를 계산\n",
        "\n",
        "5. **`num_words_upper`**  \n",
        "   - 텍스트를 단어별로 분할한 뒤, 모두 대문자인 단어의 개수를 계산\n",
        "\n",
        "6. **`num_words_title`**  \n",
        "   - 텍스트를 단어별로 분할한 뒤, 단어의 첫 글자만 대문자인 단어의 개수를 계산\n",
        "\n",
        "7. **`mean_word_len`**  \n",
        "   - 텍스트를 단어별로 분할한 뒤, 각 단어 길이의 평균을 계산\n",
        "\n",
        "8. **`num_stopwords`**  \n",
        "   - 텍스트 내 영어 불용어 개수를 계산"
      ],
      "metadata": {
        "id": "ARLqSYxsqVxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Number of words in the text ##\n",
        "train[\"num_words\"] = train[\"text\"].apply(lambda x: len(str(x).split()))\n",
        "test[\"num_words\"] = test[\"text\"].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "## Number of unique words in the text ##\n",
        "train[\"num_unique_words\"] = train[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
        "test[\"num_unique_words\"] = test[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
        "\n",
        "## Number of characters in the text ##\n",
        "train[\"num_chars\"] = train[\"text\"].apply(lambda x: len(str(x)))\n",
        "test[\"num_chars\"] = test[\"text\"].apply(lambda x: len(str(x)))\n",
        "\n",
        "## Number of punctuations in the text ##\n",
        "import string\n",
        "train[\"num_punctuations\"] =train['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
        "test[\"num_punctuations\"] =test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
        "\n",
        "## Number of title case words in the text ##\n",
        "train[\"num_words_upper\"] = train[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
        "test[\"num_words_upper\"] = test[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
        "\n",
        "## Number of title case words in the text ##\n",
        "train[\"num_words_title\"] = train[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
        "test[\"num_words_title\"] = test[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
        "\n",
        "## Average length of the words in the text ##\n",
        "train[\"mean_word_len\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "test[\"mean_word_len\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
      ],
      "metadata": {
        "id": "-lCDIwO4HEYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Number of stopwords in the text ##\n",
        "eng_stopwords = [\n",
        "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
        "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
        "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
        "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
        "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
        "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
        "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
        "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
        "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
        "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
        "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
        "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
        "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
        "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
        "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
        "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
        "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
        "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
        "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
        "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
        "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
        "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
        "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
        "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
        "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
        "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
        "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
        "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
        "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
        "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
        "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
        "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
        "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
        "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
        "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
        "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
        "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
        "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
        "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
        "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
        "    \"yourselves\"]\n",
        "train[\"num_stopwords\"] = train[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
        "test[\"num_stopwords\"] = test[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))"
      ],
      "metadata": {
        "id": "ba959-5ZHhOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean text\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "punctuation = ['.', '..', '...', ',', ':', ';', '-', '*', '\"', '!', '?']\n",
        "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "def clean_text(x):\n",
        "    x.lower()\n",
        "    for p in punctuation:\n",
        "        x.replace(p, '')\n",
        "    return x\n",
        "\n",
        "train['text_cleaned'] = train['text'].apply(lambda x: clean_text(x))\n",
        "test['text_cleaned'] = test['text'].apply(lambda x: clean_text(x))\n",
        "\n",
        "def extract_features(df):\n",
        "    df['len'] = df['text'].apply(lambda x: len(x))\n",
        "    df['n_words'] = df['text'].apply(lambda x: len(x.split(' ')))\n",
        "    df['n_.'] = df['text'].str.count('\\.')\n",
        "    df['n_...'] = df['text'].str.count('\\...')\n",
        "    df['n_,'] = df['text'].str.count('\\,')\n",
        "    df['n_:'] = df['text'].str.count('\\:')\n",
        "    df['n_;'] = df['text'].str.count('\\;')\n",
        "    df['n_-'] = df['text'].str.count('\\-')\n",
        "    df['n_?'] = df['text'].str.count('\\?')\n",
        "    df['n_!'] = df['text'].str.count('\\!')\n",
        "    df['n_\\''] = df['text'].str.count('\\'')\n",
        "    df['n_\"'] = df['text'].str.count('\\\"')\n",
        "\n",
        "    # First words in a sentence\n",
        "    df['n_The '] = df['text'].str.count('The ')\n",
        "    df['n_I '] = df['text'].str.count('I ')\n",
        "    df['n_It '] = df['text'].str.count('It ')\n",
        "    df['n_He '] = df['text'].str.count('He ')\n",
        "    df['n_Me '] = df['text'].str.count('Me ')\n",
        "    df['n_She '] = df['text'].str.count('She ')\n",
        "    df['n_We '] = df['text'].str.count('We ')\n",
        "    df['n_They '] = df['text'].str.count('They ')\n",
        "    df['n_You '] = df['text'].str.count('You ')\n",
        "    df['n_the'] = df['text_cleaned'].str.count('the ')\n",
        "    df['n_ a '] = df['text_cleaned'].str.count(' a ')\n",
        "    df['n_appear'] = df['text_cleaned'].str.count('appear')\n",
        "    df['n_little'] = df['text_cleaned'].str.count('little')\n",
        "    df['n_was '] = df['text_cleaned'].str.count('was ')\n",
        "    df['n_one '] = df['text_cleaned'].str.count('one ')\n",
        "    df['n_two '] = df['text_cleaned'].str.count('two ')\n",
        "    df['n_three '] = df['text_cleaned'].str.count('three ')\n",
        "    df['n_ten '] = df['text_cleaned'].str.count('ten ')\n",
        "    df['n_is '] = df['text_cleaned'].str.count('is ')\n",
        "    df['n_are '] = df['text_cleaned'].str.count('are ')\n",
        "    df['n_ed'] = df['text_cleaned'].str.count('ed ')\n",
        "    df['n_however'] = df['text_cleaned'].str.count('however')\n",
        "    df['n_ to '] = df['text_cleaned'].str.count(' to ')\n",
        "    df['n_into'] = df['text_cleaned'].str.count('into')\n",
        "    df['n_about '] = df['text_cleaned'].str.count('about ')\n",
        "    df['n_th'] = df['text_cleaned'].str.count('th')\n",
        "    df['n_er'] = df['text_cleaned'].str.count('er')\n",
        "    df['n_ex'] = df['text_cleaned'].str.count('ex')\n",
        "    df['n_an '] = df['text_cleaned'].str.count('an ')\n",
        "    df['n_ground'] = df['text_cleaned'].str.count('ground')\n",
        "    df['n_any'] = df['text_cleaned'].str.count('any')\n",
        "    df['n_silence'] = df['text_cleaned'].str.count('silence')\n",
        "    df['n_wall'] = df['text_cleaned'].str.count('wall')\n",
        "\n",
        "    df.drop(['text_cleaned'], axis=1, inplace=True)\n",
        "\n",
        "print('Processing train...')\n",
        "extract_features(train)\n",
        "print('Processing test...')\n",
        "extract_features(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEPrjFe-IpKJ",
        "outputId": "a6a85721-85a1-43fc-dba7-be1d76adf551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing train...\n",
            "Processing test...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "고유명사 사용 패턴 출력 -> 너무 오래걸림\n",
        "\n",
        "추후 시간 여유가 생기면 성능 개선 여부를 확인해보는 것이 좋을 듯 합니다\n",
        "\n",
        "---\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def pos_tag_text(s):\n",
        "    sents = nltk.sent_tokenize(s)\n",
        "    res = []\n",
        "    for sent in sents:\n",
        "        words = nltk.word_tokenize(sent)\n",
        "        tag_res = [a[1] for a in nltk.pos_tag(words)]\n",
        "        res.append(' '.join(tag_res))\n",
        "    return '. '.join(res)\n",
        "\n",
        "def ne_text(s):\n",
        "    sents = nltk.sent_tokenize(s)\n",
        "    res = []\n",
        "    for sent in sents:\n",
        "        words = nltk.word_tokenize(sent)\n",
        "        tag_res = nltk.pos_tag(words)\n",
        "        ne_tree = nltk.ne_chunk(tag_res)\n",
        "        list_res = nltk.tree2conlltags(ne_tree)\n",
        "        ne_res = [a[2] for a in list_res]\n",
        "        res.append(' '.join(ne_res))\n",
        "    return '. '.join(res)\n",
        "\n",
        "train['tag_txt'] = train[\"text\"].apply(pos_tag_text)\n",
        "train['ne_txt'] = train[\"text\"].apply(ne_text)\n",
        "test['tag_txt'] = test[\"text\"].apply(pos_tag_text)\n",
        "test['ne_txt'] = test[\"text\"].apply(ne_text)\n",
        "\n",
        "c_vec3 = CountVectorizer(lowercase=False)\n",
        "c_vec3.fit(train['tag_txt'].values.tolist())\n",
        "train_cvec3 = c_vec3.transform(train['tag_txt'].values.tolist()).toarray()\n",
        "test_cvec3 = c_vec3.transform(test['tag_txt'].values.tolist()).toarray()\n",
        "print(train_cvec3.shape,test_cvec3.shape)\n",
        "\n",
        "c_vec4 = CountVectorizer(lowercase=False)\n",
        "c_vec4.fit(train['ne_txt'].values.tolist())\n",
        "train_cvec4 = c_vec4.transform(train['ne_txt'].values.tolist()).toarray()\n",
        "test_cvec4 = c_vec4.transform(test['ne_txt'].values.tolist()).toarray()\n",
        "print(train_cvec4.shape,test_cvec4.shape)\n",
        "\n",
        "tf_vec5 = TfidfVectorizer(lowercase=False)\n",
        "tf_vec5.fit(train['tag_txt'].values.tolist())\n",
        "train_tf5 = tf_vec5.transform(train['tag_txt'].values.tolist()).toarray()\n",
        "test_tf5 = tf_vec5.transform(test['tag_txt'].values.tolist()).toarray()\n",
        "print(train_tf5.shape,test_tf5.shape)\n",
        "\n",
        "tf_vec6 = TfidfVectorizer(lowercase=False)\n",
        "tf_vec6.fit(train['ne_txt'].values.tolist())\n",
        "train_tf6 = tf_vec6.transform(train['ne_txt'].values.tolist()).toarray()\n",
        "test_tf6 = tf_vec6.transform(test['ne_txt'].values.tolist()).toarray()\n",
        "print(train_tf6.shape,test_tf6.shape)"
      ],
      "metadata": {
        "id": "XU6zKaC8bZUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sZRvS9kYIzBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF & SVD 메타피처\n",
        "\n",
        "- **`svd_word_0`~`svd_word_29`**  \n",
        "  워드 n-그램(1–3) TF-IDF 벡터를 TruncatedSVD(30차원)로 축소한 주성분  \n",
        "\n",
        "- **`svd_char_0`~`svd_char_29`**  \n",
        "  문자 n-그램(3–7) TF-IDF 벡터를 TruncatedSVD(30차원)로 축소한 주성분"
      ],
      "metadata": {
        "id": "eRIgZTxIuxl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 참고용) 약 10분 걸림\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition         import TruncatedSVD\n",
        "\n",
        "# 1) WORD n-gram TF-IDF\n",
        "tfidf_vec = TfidfVectorizer(ngram_range=(1,3), max_df=0.8, sublinear_tf=True)\n",
        "tfidf_vec.fit(train['text'])\n",
        "train_tfidf = tfidf_vec.transform(train['text'])\n",
        "test_tfidf  = tfidf_vec.transform(test['text'])\n",
        "\n",
        "# 2) SVD\n",
        "svd = TruncatedSVD(n_components=30, random_state=42)\n",
        "svd.fit(train_tfidf)\n",
        "train_svd = pd.DataFrame(svd.transform(train_tfidf),\n",
        "                         columns=[f'svd_word_{i}' for i in range(30)])\n",
        "test_svd  = pd.DataFrame(svd.transform(test_tfidf),\n",
        "                         columns=[f'svd_word_{i}' for i in range(30)])\n",
        "\n",
        "# 3) CHAR n-gram TF-IDF\n",
        "tfidf_char = TfidfVectorizer(analyzer='char', ngram_range=(3,7),\n",
        "                             max_df=0.8, sublinear_tf=True)\n",
        "tfidf_char.fit(train['text'])\n",
        "train_tfidf_char = tfidf_char.transform(train['text'])\n",
        "test_tfidf_char  = tfidf_char.transform(test['text'])\n",
        "\n",
        "# 4) SVD (char)\n",
        "svd2 = TruncatedSVD(n_components=30, random_state=42)\n",
        "svd2.fit(train_tfidf_char)\n",
        "train_svd2 = pd.DataFrame(svd2.transform(train_tfidf_char),\n",
        "                          columns=[f'svd_char_{i}' for i in range(30)])\n",
        "test_svd2  = pd.DataFrame(svd2.transform(test_tfidf_char),\n",
        "                          columns=[f'svd_char_{i}' for i in range(30)])"
      ],
      "metadata": {
        "id": "VpruWYeHKlyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes OOF 메타피처\n",
        "\n",
        "- **벡터화**: 워드 n-그램(1-3) TF-IDF(max_features=5000, sublinear_tf=True)  \n",
        "- **CV 설정**: 5-Fold StratifiedKFold(shuffle=True, random_state=42)  \n",
        "- **모델 학습**: 각 Fold에서 MultinomialNB(alpha=0.1) 학습  \n",
        "- **메타피처**:  \n",
        "  - `meta_train`에 각 validation 분할의 `predict_proba` 결과 삽입 (OOF)  \n",
        "  - `meta_test`에 test 세트에 대한 `predict_proba` 평균값 저장  \n"
      ],
      "metadata": {
        "id": "hdzxBm2cvLrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# 클래스 수 확인\n",
        "n_classes = len(train['author'].unique())\n",
        "\n",
        "# 1. TF-IDF (단어 기반)\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=5000, sublinear_tf=True)\n",
        "X = tfidf.fit_transform(train['text'])\n",
        "X_test = tfidf.transform(test['text'])\n",
        "y = train['author'].values\n",
        "\n",
        "# 2. Naive Bayes + Stratified KFold\n",
        "meta_train = np.zeros((X.shape[0], n_classes))\n",
        "meta_test = np.zeros((X_test.shape[0], n_classes))\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    print(f\"Fold {fold+1}\")\n",
        "\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    model = MultinomialNB(alpha=0.1)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    meta_train[val_idx] = model.predict_proba(X_val)\n",
        "    meta_test += model.predict_proba(X_test) / skf.n_splits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CidGQEGMLHU",
        "outputId": "1a265b25-9c5c-4326-dad4-52896ce5971a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Fold 2\n",
            "Fold 3\n",
            "Fold 4\n",
            "Fold 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "meta_train_df = pd.DataFrame(meta_train, columns=[f'nb_class_{i}' for i in range(n_classes)])\n",
        "meta_test_df = pd.DataFrame(meta_test, columns=[f'nb_class_{i}' for i in range(n_classes)])\n",
        "\n",
        "train = pd.concat([train.reset_index(drop=True), meta_train_df], axis=1)\n",
        "test = pd.concat([test.reset_index(drop=True), meta_test_df], axis=1)\n",
        "\n",
        "# 중복된 nb_class_* 컬럼 제거\n",
        "train = train.loc[:, ~train.columns.duplicated()]\n",
        "test = test.loc[:, ~test.columns.duplicated()]"
      ],
      "metadata": {
        "id": "CV34cf58MOIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문자 유형 비율 메타피처\n",
        "\n",
        "- 숫자, 영어, 한글 문자의 비율을 통해 저자별 문자 사용 습관을 포착\n",
        "- 전체 길이 대비 각 문자 종류의 비중\n"
      ],
      "metadata": {
        "id": "USp4kB1bqysF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def char_type_features(df, text_col='text'):\n",
        "    ct = pd.DataFrame(index=df.index)\n",
        "    # 전체 문자 수\n",
        "    ct['total_chars'] = df[text_col].str.len()\n",
        "    # 숫자\n",
        "    ct['digit_count'] = df[text_col].str.count(r'\\d')\n",
        "    ct['digit_ratio'] = ct['digit_count'] / (ct['total_chars'] + 1e-9)\n",
        "    # 영어\n",
        "    ct['eng_count'] = df[text_col].str.count(r'[A-Za-z]')\n",
        "    ct['eng_ratio'] = ct['eng_count'] / (ct['total_chars'] + 1e-9)\n",
        "    return ct.fillna(0)\n",
        "\n",
        "# train/test 각각에 적용\n",
        "train_ct = char_type_features(train, text_col='text')\n",
        "test_ct  = char_type_features(test,  text_col='text')\n",
        "\n",
        "train = pd.concat([train, train_ct], axis=1).fillna(0)\n",
        "test  = pd.concat([test,  test_ct ], axis=1).fillna(0)\n",
        "\n",
        "# 결과 확인\n",
        "print(\"train.shape:\", meta_train.shape)\n",
        "print(\"test.shape: \", meta_test.shape)\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "Hq2dFuGfq0yw",
        "outputId": "04d0c099-f082-4d53-fe95-be8a591c7912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.shape: (54879, 5)\n",
            "test.shape:  (19617, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                               text  author  \\\n",
              "0      0  He was almost choking. There was so much, so m...       3   \n",
              "1      1             “Your sister asked for it, I suppose?”       2   \n",
              "2      2   She was engaged one day as she walked, in per...       1   \n",
              "3      3  The captain was in the porch, keeping himself ...       4   \n",
              "4      4  “Have mercy, gentlemen!” odin flung up his han...       3   \n",
              "\n",
              "   num_words  num_unique_words  num_chars  num_punctuations  num_words_upper  \\\n",
              "0         46                39        240                 8                0   \n",
              "1          7                 7         38                 2                1   \n",
              "2         57                50        320                 9                0   \n",
              "3         58                49        319                18                0   \n",
              "4         39                36        228                13                0   \n",
              "\n",
              "   num_words_title  mean_word_len  ...  nb_class_0  nb_class_1  nb_class_2  \\\n",
              "0                4       4.239130  ...    0.068573    0.011556    0.052782   \n",
              "1                2       4.571429  ...    0.282354    0.386041    0.074021   \n",
              "2                4       4.614035  ...    0.105101    0.865957    0.003361   \n",
              "3                7       4.517241  ...    0.013569    0.003810    0.276248   \n",
              "4                4       4.871795  ...    0.072644    0.002546    0.071292   \n",
              "\n",
              "   nb_class_3  nb_class_4  total_chars  digit_count  digit_ratio  eng_count  \\\n",
              "0    0.853063    0.014027          240            0          0.0        187   \n",
              "1    0.237655    0.019929           38            0          0.0         28   \n",
              "2    0.021768    0.003813          320            0          0.0        253   \n",
              "3    0.007511    0.698863          319            0          0.0        242   \n",
              "4    0.777851    0.075667          228            0          0.0        171   \n",
              "\n",
              "   eng_ratio  \n",
              "0   0.779167  \n",
              "1   0.736842  \n",
              "2   0.790625  \n",
              "3   0.758621  \n",
              "4   0.750000  \n",
              "\n",
              "[5 rows x 66 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39f27092-96c7-4211-94bb-bc0b69be01ab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_unique_words</th>\n",
              "      <th>num_chars</th>\n",
              "      <th>num_punctuations</th>\n",
              "      <th>num_words_upper</th>\n",
              "      <th>num_words_title</th>\n",
              "      <th>mean_word_len</th>\n",
              "      <th>...</th>\n",
              "      <th>nb_class_0</th>\n",
              "      <th>nb_class_1</th>\n",
              "      <th>nb_class_2</th>\n",
              "      <th>nb_class_3</th>\n",
              "      <th>nb_class_4</th>\n",
              "      <th>total_chars</th>\n",
              "      <th>digit_count</th>\n",
              "      <th>digit_ratio</th>\n",
              "      <th>eng_count</th>\n",
              "      <th>eng_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "      <td>3</td>\n",
              "      <td>46</td>\n",
              "      <td>39</td>\n",
              "      <td>240</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4.239130</td>\n",
              "      <td>...</td>\n",
              "      <td>0.068573</td>\n",
              "      <td>0.011556</td>\n",
              "      <td>0.052782</td>\n",
              "      <td>0.853063</td>\n",
              "      <td>0.014027</td>\n",
              "      <td>240</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>187</td>\n",
              "      <td>0.779167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>0.282354</td>\n",
              "      <td>0.386041</td>\n",
              "      <td>0.074021</td>\n",
              "      <td>0.237655</td>\n",
              "      <td>0.019929</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28</td>\n",
              "      <td>0.736842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>50</td>\n",
              "      <td>320</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4.614035</td>\n",
              "      <td>...</td>\n",
              "      <td>0.105101</td>\n",
              "      <td>0.865957</td>\n",
              "      <td>0.003361</td>\n",
              "      <td>0.021768</td>\n",
              "      <td>0.003813</td>\n",
              "      <td>320</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>253</td>\n",
              "      <td>0.790625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The captain was in the porch, keeping himself ...</td>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>49</td>\n",
              "      <td>319</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>4.517241</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013569</td>\n",
              "      <td>0.003810</td>\n",
              "      <td>0.276248</td>\n",
              "      <td>0.007511</td>\n",
              "      <td>0.698863</td>\n",
              "      <td>319</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>242</td>\n",
              "      <td>0.758621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "      <td>3</td>\n",
              "      <td>39</td>\n",
              "      <td>36</td>\n",
              "      <td>228</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4.871795</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072644</td>\n",
              "      <td>0.002546</td>\n",
              "      <td>0.071292</td>\n",
              "      <td>0.777851</td>\n",
              "      <td>0.075667</td>\n",
              "      <td>228</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>171</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 66 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39f27092-96c7-4211-94bb-bc0b69be01ab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39f27092-96c7-4211-94bb-bc0b69be01ab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39f27092-96c7-4211-94bb-bc0b69be01ab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-25e8af80-9089-476b-a75f-b972b28b2a71\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25e8af80-9089-476b-a75f-b972b28b2a71')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-25e8af80-9089-476b-a75f-b972b28b2a71 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.columns)\n",
        "print(train.shape[1])  # 전체 피처 수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0T9T3F404Cu",
        "outputId": "c5a0dfd4-78bf-4111-fe1b-606cecb24d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['index', 'text', 'author', 'num_words', 'num_unique_words', 'num_chars',\n",
            "       'num_punctuations', 'num_words_upper', 'num_words_title',\n",
            "       'mean_word_len', 'num_stopwords', 'len', 'n_words', 'n_.', 'n_...',\n",
            "       'n_,', 'n_:', 'n_;', 'n_-', 'n_?', 'n_!', 'n_'', 'n_\"', 'n_The ',\n",
            "       'n_I ', 'n_It ', 'n_He ', 'n_Me ', 'n_She ', 'n_We ', 'n_They ',\n",
            "       'n_You ', 'n_the', 'n_ a ', 'n_appear', 'n_little', 'n_was ', 'n_one ',\n",
            "       'n_two ', 'n_three ', 'n_ten ', 'n_is ', 'n_are ', 'n_ed', 'n_however',\n",
            "       'n_ to ', 'n_into', 'n_about ', 'n_th', 'n_er', 'n_ex', 'n_an ',\n",
            "       'n_ground', 'n_any', 'n_silence', 'n_wall', 'nb_class_0', 'nb_class_1',\n",
            "       'nb_class_2', 'nb_class_3', 'nb_class_4', 'total_chars', 'digit_count',\n",
            "       'digit_ratio', 'eng_count', 'eng_ratio'],\n",
            "      dtype='object')\n",
            "66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **모델을 이용하여 피처 생성**"
      ],
      "metadata": {
        "id": "4UQyWTL9CsvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LogisticRegression으로 피처 생성**"
      ],
      "metadata": {
        "id": "8IXFNFFoxbgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 피처 벡터화\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "tfidf2 = TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 3), min_df=50)\n",
        "X = tfidf2.fit_transform(train['text'])\n",
        "X_test = tfidf2.transform(test['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INhDYUzwveeQ",
        "outputId": "19c26d99-dcb3-4e7f-c937-89646caef29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_fold = 5\n",
        "seed = 42\n",
        "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
      ],
      "metadata": {
        "id": "3bbItXcO9916"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "y = train['author'].values\n",
        "n_class = len(np.unique(y))\n",
        "\n",
        "# 예측 결과 저장용\n",
        "p = np.zeros((X.shape[0], n_class))\n",
        "p_tst = np.zeros((X_test.shape[0], n_class))\n",
        "\n",
        "# Stratified K-Fold 교차검증\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for i_cv, (i_trn, i_val) in enumerate(cv.split(X, y), 1):\n",
        "    print(f\"Fold {i_cv}\")\n",
        "\n",
        "    clf = LogisticRegression(max_iter=1000, C=1.0, solver='liblinear', multi_class='ovr')\n",
        "    clf.fit(X[i_trn], y[i_trn])\n",
        "\n",
        "    # 검증셋 예측 저장\n",
        "    p[i_val, :] = clf.predict_proba(X[i_val])\n",
        "\n",
        "    # 테스트셋 예측 누적 평균\n",
        "    p_tst += clf.predict_proba(X_test) / cv.n_splits"
      ],
      "metadata": {
        "id": "lxioWS0PlANT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbccaac5-bac6-48ac-cd88-7e2a77b96af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 로지스틱 예측 결과 확인\n",
        "print(p)\n",
        "print(p_tst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8oGa0JuNEoX",
        "outputId": "440b87e9-e62b-4b38-d4c5-96d98ffd42d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.06189655 0.03873073 0.02612818 0.85686559 0.01637895]\n",
            " [0.4160363  0.34474796 0.05481215 0.15570115 0.02870244]\n",
            " [0.26537439 0.67465412 0.00167294 0.05461705 0.00368151]\n",
            " ...\n",
            " [0.07944283 0.70219475 0.01780089 0.13582431 0.06473721]\n",
            " [0.07170358 0.02215117 0.27386091 0.60806033 0.02422401]\n",
            " [0.37257146 0.04392143 0.11611735 0.44741359 0.01997616]]\n",
            "[[0.07791363 0.45494121 0.38854873 0.06687426 0.01172217]\n",
            " [0.12064811 0.70770804 0.01609679 0.06491018 0.09063687]\n",
            " [0.75956974 0.05041887 0.10398966 0.06875483 0.0172669 ]\n",
            " ...\n",
            " [0.23679087 0.67850783 0.00359074 0.07235674 0.00875382]\n",
            " [0.01828719 0.825399   0.08690073 0.03792794 0.03148514]\n",
            " [0.39121226 0.02044296 0.17828803 0.13872753 0.27132922]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# csv 파일 추출\n",
        "pd.DataFrame(p).to_csv('logistic_train.csv', index=False)\n",
        "pd.DataFrame(p_tst).to_csv('logistic_test.csv', index=False)"
      ],
      "metadata": {
        "id": "Q_OUIuutSoLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NN으로 피처 생성**"
      ],
      "metadata": {
        "id": "oBsoIvZDw-MU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing > Embedding > Pooling > Hidden Layer(2) > Output"
      ],
      "metadata": {
        "id": "DNphcrfsg5Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Dense,Input,Conv1D,Embedding, GlobalMaxPooling1D, GlobalAveragePooling1D, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model,Sequential, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import gc"
      ],
      "metadata": {
        "id": "Xt018FYKDCZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **적절한 패딩 길이 찾기**"
      ],
      "metadata": {
        "id": "-TUMgMA9dau6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=30000)\n",
        "tokenizer.fit_on_texts(train['text'])\n",
        "train_x_tmp = tokenizer.texts_to_sequences(train['text'])"
      ],
      "metadata": {
        "id": "yoVOe7E9bQu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_lengths = [len(seq) for seq in train_x_tmp]\n",
        "print(\"Max length:\", max(sequence_lengths))\n",
        "print(\"95 percentile:\", np.percentile(sequence_lengths, 95))\n",
        "print(\"Median length:\", np.median(sequence_lengths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXnka5IJddd_",
        "outputId": "588aba53-5299-40cb-9d56-777659bdfd8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length: 473\n",
            "95 percentile: 160.0\n",
            "Median length: 23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(각 문장을 정수 인덱스 시퀀스로 변환한 결과) 전체 데이터의 50%는 23 토큰 이하로 매우 짧음\n",
        "\n",
        "95%는 160 토큰 이하로, 이보다 긴 시퀀스는 거의 X\n",
        "\n",
        "473까지 가는 긴 문장은 극소수이며, 이들을 모두 살리려면 오히려 모델 학습에 비효율이 발생!\n",
        "\n",
        "✅ 최적의 MAX_LEN 추천\n",
        "- 160: 95% 문장을 커버 → ✅ 가장 균형 잡힌 선택\n",
        "\n",
        "- 200: 약간의 여유를 두고 자르기 → 가능\n",
        "\n",
        "- 256 이상: 필요 없으며, 오히려 padding이 과도해질 가능성 있음\n",
        "\n",
        "> 160보다는 100으로 잡았을 때 성능이 더 향상되었으므로 100으로 진행"
      ],
      "metadata": {
        "id": "jP0bKR7kd2In"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average pooling 적용\n",
        "# Hidden Layer 2개\n",
        "\n",
        "import json\n",
        "\n",
        "\n",
        "def get_nn_feats2(rnd=1):\n",
        "    train_pred, test_pred = np.zeros((54879,5)),np.zeros((19617,5))\n",
        "    best_val_train_pred, best_val_test_pred = np.zeros((54879,5)),np.zeros((19617,5))\n",
        "\n",
        "    best_fold_loss = float('inf')\n",
        "    best_fold_idx = -1\n",
        "    best_fold_metrics = {}\n",
        "\n",
        "    # 파라미터 설정\n",
        "    FEAT_CNT = 10\n",
        "    NUM_WORDS = 30000\n",
        "    N = 10\n",
        "    MAX_LEN = 100\n",
        "    NUM_CLASSES = 5\n",
        "    MODEL_P = 'nn_model.h5'\n",
        "\n",
        "    tmp_X = train['text']\n",
        "    tmp_Y = train['author']\n",
        "    tmp_X_test = test['text']\n",
        "    # Tokenizing\n",
        "    tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
        "    tokenizer.fit_on_texts(tmp_X)\n",
        "    # text to sequence\n",
        "    # padding\n",
        "    ttrain_x = tokenizer.texts_to_sequences(tmp_X)\n",
        "    ttrain_x = pad_sequences(ttrain_x, maxlen=MAX_LEN)\n",
        "\n",
        "    ttest_x = tokenizer.texts_to_sequences(tmp_X_test)\n",
        "    ttest_x = pad_sequences(ttest_x, maxlen=MAX_LEN)\n",
        "\n",
        "    # label one-hot encoding\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    lb.fit(tmp_Y)\n",
        "    ttrain_y = lb.transform(tmp_Y)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=FEAT_CNT, shuffle=True, random_state=233*rnd)\n",
        "    for fold_idx, (train_index, test_index) in enumerate(skf.split(ttrain_x, tmp_Y)):\n",
        "        # 입력층\n",
        "        input_layer = Input(shape=(MAX_LEN,))\n",
        "\n",
        "        # 임베딩층\n",
        "        embedding = Embedding(input_dim=NUM_WORDS, output_dim=N, input_length=MAX_LEN)(input_layer)\n",
        "\n",
        "        # 평균 풀링 + 최대 풀링\n",
        "        avg_pool = GlobalAveragePooling1D()(embedding)\n",
        "        #max_pool = GlobalMaxPooling1D()(embedding)\n",
        "\n",
        "        # 두 풀링 결과를 합치기\n",
        "        #concat = Concatenate()([avg_pool, max_pool])  # shape: (None, 2 * EMBEDDING_DIM)\n",
        "\n",
        "        # 밀집층\n",
        "        #x = Dense(64, activation='relu')(concat)\n",
        "        x = Dense(64, activation='relu')(avg_pool)\n",
        "        x = Dropout(0.1)(x)\n",
        "        x = Dense(32, activation='relu')(x)\n",
        "        x = Dropout(0.1)(x)\n",
        "        output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "        # 모델 정의\n",
        "        model = Model(inputs=input_layer, outputs=output)\n",
        "        model.compile(optimizer='adam',\n",
        "                      loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        mc = ModelCheckpoint(filepath=MODEL_P, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "        es=EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "        np.random.seed(42)\n",
        "        history = model.fit(ttrain_x[train_index], ttrain_y[train_index],\n",
        "                  validation_split=0.3,\n",
        "                  batch_size=64, epochs=20,\n",
        "                  verbose=1,\n",
        "                  callbacks=[mc,es],\n",
        "                  shuffle=False\n",
        "                 )\n",
        "\n",
        "        # 현재 fold의 best val_loss와 그때의 val_accuracy\n",
        "        current_best_val_loss = min(history.history['val_loss'])\n",
        "        current_best_val_acc = max(history.history['val_accuracy'])\n",
        "\n",
        "        if current_best_val_loss < best_fold_loss:\n",
        "            best_fold_loss = current_best_val_loss\n",
        "            best_fold_idx = fold_idx\n",
        "            best_fold_metrics = {'fold': fold_idx, 'val_loss': round(current_best_val_loss, 4),\n",
        "                                 'val_accuracy': round(current_best_val_acc, 4) }\n",
        "\n",
        "        # 마지막에 JSON으로 저장\n",
        "        with open('best_val_result.json', 'w') as f:\n",
        "            json.dump(best_fold_metrics, f)\n",
        "\n",
        "        print(\"✅ Best fold info saved to best_val_result.json\")\n",
        "\n",
        "        # feature 생성 1\n",
        "        train_pred[test_index] = model.predict(ttrain_x[test_index])\n",
        "        test_pred += model.predict(ttest_x)/FEAT_CNT\n",
        "\n",
        "        # feature 생성 2\n",
        "        model = load_model(MODEL_P)\n",
        "        best_val_train_pred[test_index] = model.predict(ttrain_x[test_index])\n",
        "        best_val_test_pred += model.predict(ttest_x)/FEAT_CNT\n",
        "\n",
        "        del model\n",
        "        gc.collect()\n",
        "        print('------------------')\n",
        "\n",
        "    return train_pred,test_pred,best_val_train_pred,best_val_test_pred\n",
        "\n",
        "nn_train1,nn_test1,nn_train2,nn_test2 = get_nn_feats2(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aead1ec-16a0-4a69-c1f2-58a7245ad3b0",
        "id": "7tH0h3JMjibS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2839 - loss: 1.5491\n",
            "Epoch 1: val_loss improved from inf to 1.16502, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2847 - loss: 1.5482 - val_accuracy: 0.5347 - val_loss: 1.1650\n",
            "Epoch 2/20\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5451 - loss: 1.1240\n",
            "Epoch 2: val_loss improved from 1.16502 to 0.99614, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5453 - loss: 1.1235 - val_accuracy: 0.6107 - val_loss: 0.9961\n",
            "Epoch 3/20\n",
            "\u001b[1m532/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6427 - loss: 0.9138\n",
            "Epoch 3: val_loss improved from 0.99614 to 0.90425, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6430 - loss: 0.9132 - val_accuracy: 0.6594 - val_loss: 0.9043\n",
            "Epoch 4/20\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7071 - loss: 0.7742\n",
            "Epoch 4: val_loss improved from 0.90425 to 0.87923, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7073 - loss: 0.7738 - val_accuracy: 0.6759 - val_loss: 0.8792\n",
            "Epoch 5/20\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.6730\n",
            "Epoch 5: val_loss improved from 0.87923 to 0.83030, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7530 - loss: 0.6730 - val_accuracy: 0.6993 - val_loss: 0.8303\n",
            "Epoch 6/20\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.5913\n",
            "Epoch 6: val_loss improved from 0.83030 to 0.73532, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7858 - loss: 0.5910 - val_accuracy: 0.7352 - val_loss: 0.7353\n",
            "Epoch 7/20\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8152 - loss: 0.5213\n",
            "Epoch 7: val_loss did not improve from 0.73532\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8152 - loss: 0.5212 - val_accuracy: 0.7272 - val_loss: 0.7686\n",
            "Epoch 8/20\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8147 - loss: 0.5120\n",
            "Epoch 8: val_loss improved from 0.73532 to 0.72399, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8149 - loss: 0.5117 - val_accuracy: 0.7482 - val_loss: 0.7240\n",
            "Epoch 9/20\n",
            "\u001b[1m532/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8466 - loss: 0.4431\n",
            "Epoch 9: val_loss did not improve from 0.72399\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8466 - loss: 0.4432 - val_accuracy: 0.7205 - val_loss: 0.8006\n",
            "Epoch 10/20\n",
            "\u001b[1m532/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 0.4086\n",
            "Epoch 10: val_loss improved from 0.72399 to 0.71059, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8588 - loss: 0.4088 - val_accuracy: 0.7581 - val_loss: 0.7106\n",
            "Epoch 11/20\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8607 - loss: 0.4001\n",
            "Epoch 11: val_loss did not improve from 0.71059\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8607 - loss: 0.4000 - val_accuracy: 0.7596 - val_loss: 0.7294\n",
            "Epoch 12/20\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8724 - loss: 0.3741\n",
            "Epoch 12: val_loss did not improve from 0.71059\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8724 - loss: 0.3741 - val_accuracy: 0.7565 - val_loss: 0.7513\n",
            "✅ Best fold info saved to best_val_result.json\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "------------------\n",
            "Epoch 1/20\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2985 - loss: 1.5460\n",
            "Epoch 1: val_loss improved from inf to 1.13821, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2989 - loss: 1.5455 - val_accuracy: 0.5694 - val_loss: 1.1382\n",
            "Epoch 2/20\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5635 - loss: 1.1053\n",
            "Epoch 2: val_loss improved from 1.13821 to 0.94326, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5636 - loss: 1.1052 - val_accuracy: 0.6399 - val_loss: 0.9433\n",
            "Epoch 3/20\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6581 - loss: 0.8912\n",
            "Epoch 3: val_loss improved from 0.94326 to 0.87526, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6582 - loss: 0.8906 - val_accuracy: 0.6686 - val_loss: 0.8753\n",
            "Epoch 4/20\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7094 - loss: 0.7659\n",
            "Epoch 4: val_loss improved from 0.87526 to 0.81655, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7094 - loss: 0.7659 - val_accuracy: 0.6908 - val_loss: 0.8166\n",
            "Epoch 5/20\n",
            "\u001b[1m532/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7484 - loss: 0.6805\n",
            "Epoch 5: val_loss did not improve from 0.81655\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.7486 - loss: 0.6802 - val_accuracy: 0.6805 - val_loss: 0.8377\n",
            "Epoch 6/20\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7759 - loss: 0.6140\n",
            "Epoch 6: val_loss improved from 0.81655 to 0.76231, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7760 - loss: 0.6137 - val_accuracy: 0.7191 - val_loss: 0.7623\n",
            "Epoch 7/20\n",
            "\u001b[1m531/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7967 - loss: 0.5668\n",
            "Epoch 7: val_loss did not improve from 0.76231\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7969 - loss: 0.5664 - val_accuracy: 0.7197 - val_loss: 0.7711\n",
            "Epoch 8/20\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8217 - loss: 0.5048\n",
            "Epoch 8: val_loss improved from 0.76231 to 0.75482, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8217 - loss: 0.5048 - val_accuracy: 0.7354 - val_loss: 0.7548\n",
            "Epoch 9/20\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8220 - loss: 0.4979\n",
            "Epoch 9: val_loss did not improve from 0.75482\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8220 - loss: 0.4979 - val_accuracy: 0.7294 - val_loss: 0.7921\n",
            "Epoch 10/20\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8321 - loss: 0.4688\n",
            "Epoch 10: val_loss did not improve from 0.75482\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8321 - loss: 0.4687 - val_accuracy: 0.7301 - val_loss: 0.8260\n",
            "✅ Best fold info saved to best_val_result.json\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "------------------\n",
            "Epoch 1/20\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2913 - loss: 1.5496\n",
            "Epoch 1: val_loss improved from inf to 1.28054, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2918 - loss: 1.5490 - val_accuracy: 0.5198 - val_loss: 1.2805\n",
            "Epoch 2/20\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5015 - loss: 1.2125\n",
            "Epoch 2: val_loss improved from 1.28054 to 1.05009, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5022 - loss: 1.2110 - val_accuracy: 0.5898 - val_loss: 1.0501\n",
            "Epoch 3/20\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6280 - loss: 0.9367\n",
            "Epoch 3: val_loss improved from 1.05009 to 0.92131, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6283 - loss: 0.9361 - val_accuracy: 0.6454 - val_loss: 0.9213\n",
            "Epoch 4/20\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6934 - loss: 0.7984\n",
            "Epoch 4: val_loss improved from 0.92131 to 0.79609, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6935 - loss: 0.7983 - val_accuracy: 0.7017 - val_loss: 0.7961\n",
            "Epoch 5/20\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7302 - loss: 0.7115\n",
            "Epoch 5: val_loss did not improve from 0.79609\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7303 - loss: 0.7112 - val_accuracy: 0.6821 - val_loss: 0.8231\n",
            "Epoch 6/20\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7678 - loss: 0.6274\n",
            "Epoch 6: val_loss improved from 0.79609 to 0.78864, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7679 - loss: 0.6273 - val_accuracy: 0.7037 - val_loss: 0.7886\n",
            "Epoch 7/20\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.5689\n",
            "Epoch 7: val_loss improved from 0.78864 to 0.74753, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7935 - loss: 0.5688 - val_accuracy: 0.7285 - val_loss: 0.7475\n",
            "Epoch 8/20\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8157 - loss: 0.5162\n",
            "Epoch 8: val_loss did not improve from 0.74753\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8157 - loss: 0.5162 - val_accuracy: 0.7040 - val_loss: 0.8067\n",
            "Epoch 9/20\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8267 - loss: 0.4878\n",
            "Epoch 9: val_loss did not improve from 0.74753\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8267 - loss: 0.4878 - val_accuracy: 0.6944 - val_loss: 0.8553\n",
            "✅ Best fold info saved to best_val_result.json\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "------------------\n",
            "Epoch 1/20\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2894 - loss: 1.5497\n",
            "Epoch 1: val_loss improved from inf to 1.23587, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2899 - loss: 1.5492 - val_accuracy: 0.5007 - val_loss: 1.2359\n",
            "Epoch 2/20\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5122 - loss: 1.1929\n",
            "Epoch 2: val_loss improved from 1.23587 to 1.10041, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5124 - loss: 1.1926 - val_accuracy: 0.5424 - val_loss: 1.1004\n",
            "Epoch 3/20\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6220 - loss: 0.9625\n",
            "Epoch 3: val_loss improved from 1.10041 to 0.98415, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6221 - loss: 0.9624 - val_accuracy: 0.6022 - val_loss: 0.9841\n",
            "Epoch 4/20\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6818 - loss: 0.8240\n",
            "Epoch 4: val_loss improved from 0.98415 to 0.87199, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6819 - loss: 0.8237 - val_accuracy: 0.6618 - val_loss: 0.8720\n",
            "Epoch 5/20\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7269 - loss: 0.7277\n",
            "Epoch 5: val_loss improved from 0.87199 to 0.77261, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7271 - loss: 0.7272 - val_accuracy: 0.7124 - val_loss: 0.7726\n",
            "Epoch 6/20\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7630 - loss: 0.6428\n",
            "Epoch 6: val_loss improved from 0.77261 to 0.73869, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7631 - loss: 0.6426 - val_accuracy: 0.7317 - val_loss: 0.7387\n",
            "Epoch 7/20\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7967 - loss: 0.5659\n",
            "Epoch 7: val_loss did not improve from 0.73869\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7967 - loss: 0.5659 - val_accuracy: 0.7158 - val_loss: 0.7750\n",
            "Epoch 8/20\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8144 - loss: 0.5219\n",
            "Epoch 8: val_loss did not improve from 0.73869\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8144 - loss: 0.5217 - val_accuracy: 0.7201 - val_loss: 0.7871\n",
            "✅ Best fold info saved to best_val_result.json\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "------------------\n",
            "Epoch 1/20\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2763 - loss: 1.5534\n",
            "Epoch 1: val_loss improved from inf to 1.37878, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.2769 - loss: 1.5527 - val_accuracy: 0.4007 - val_loss: 1.3788\n",
            "Epoch 2/20\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4750 - loss: 1.2725\n",
            "Epoch 2: val_loss improved from 1.37878 to 0.96541, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4753 - loss: 1.2719 - val_accuracy: 0.6253 - val_loss: 0.9654\n",
            "Epoch 3/20\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6206 - loss: 0.9420\n",
            "Epoch 3: val_loss improved from 0.96541 to 0.86837, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6208 - loss: 0.9414 - val_accuracy: 0.6585 - val_loss: 0.8684\n",
            "Epoch 4/20\n",
            "\u001b[1m531/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6761 - loss: 0.8050\n",
            "Epoch 4: val_loss improved from 0.86837 to 0.83048, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6763 - loss: 0.8047 - val_accuracy: 0.6793 - val_loss: 0.8305\n",
            "Epoch 5/20\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7233 - loss: 0.7185\n",
            "Epoch 5: val_loss improved from 0.83048 to 0.81884, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7233 - loss: 0.7183 - val_accuracy: 0.6850 - val_loss: 0.8188\n",
            "Epoch 6/20\n",
            "\u001b[1m535/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7562 - loss: 0.6455\n",
            "Epoch 6: val_loss improved from 0.81884 to 0.76690, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7563 - loss: 0.6452 - val_accuracy: 0.7170 - val_loss: 0.7669\n",
            "Epoch 7/20\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7918 - loss: 0.5748\n",
            "Epoch 7: val_loss did not improve from 0.76690\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7918 - loss: 0.5748 - val_accuracy: 0.6691 - val_loss: 0.9400\n",
            "Epoch 8/20\n",
            "\u001b[1m532/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8133 - loss: 0.5228\n",
            "Epoch 8: val_loss did not improve from 0.76690\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8134 - loss: 0.5225 - val_accuracy: 0.7056 - val_loss: 0.8562\n",
            "✅ Best fold info saved to best_val_result.json\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "------------------\n",
            "Epoch 1/20\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2932 - loss: 1.5471\n",
            "Epoch 1: val_loss improved from inf to 1.26844, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2937 - loss: 1.5465 - val_accuracy: 0.4439 - val_loss: 1.2684\n",
            "Epoch 2/20\n",
            "\u001b[1m532/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5281 - loss: 1.1584\n",
            "Epoch 2: val_loss improved from 1.26844 to 0.94773, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5288 - loss: 1.1569 - val_accuracy: 0.6424 - val_loss: 0.9477\n",
            "Epoch 3/20\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6476 - loss: 0.9091\n",
            "Epoch 3: val_loss improved from 0.94773 to 0.86582, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6478 - loss: 0.9087 - val_accuracy: 0.6726 - val_loss: 0.8658\n",
            "Epoch 4/20\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7140 - loss: 0.7648\n",
            "Epoch 4: val_loss improved from 0.86582 to 0.77171, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7140 - loss: 0.7647 - val_accuracy: 0.7163 - val_loss: 0.7717\n",
            "Epoch 5/20\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7576 - loss: 0.6577\n",
            "Epoch 5: val_loss did not improve from 0.77171\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7576 - loss: 0.6577 - val_accuracy: 0.6903 - val_loss: 0.8070\n",
            "Epoch 6/20\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7927 - loss: 0.5746\n",
            "Epoch 6: val_loss improved from 0.77171 to 0.74861, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7928 - loss: 0.5745 - val_accuracy: 0.7241 - val_loss: 0.7486\n",
            "Epoch 7/20\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8035 - loss: 0.5393\n",
            "Epoch 7: val_loss improved from 0.74861 to 0.72378, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8036 - loss: 0.5392 - val_accuracy: 0.7384 - val_loss: 0.7238\n",
            "Epoch 8/20\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8259 - loss: 0.4891\n",
            "Epoch 8: val_loss improved from 0.72378 to 0.69742, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8260 - loss: 0.4889 - val_accuracy: 0.7531 - val_loss: 0.6974\n",
            "Epoch 9/20\n",
            "\u001b[1m531/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8376 - loss: 0.4596\n",
            "Epoch 9: val_loss improved from 0.69742 to 0.68965, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8377 - loss: 0.4592 - val_accuracy: 0.7620 - val_loss: 0.6896\n",
            "Epoch 10/20\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8439 - loss: 0.4356\n",
            "Epoch 10: val_loss did not improve from 0.68965\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8440 - loss: 0.4356 - val_accuracy: 0.7629 - val_loss: 0.7028\n",
            "Epoch 11/20\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8499 - loss: 0.4236\n",
            "Epoch 11: val_loss did not improve from 0.68965\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8500 - loss: 0.4232 - val_accuracy: 0.7571 - val_loss: 0.7283\n",
            "✅ Best fold info saved to best_val_result.json\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "------------------\n",
            "Epoch 1/20\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2947 - loss: 1.5489\n",
            "Epoch 1: val_loss improved from inf to 1.17466, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2957 - loss: 1.5477 - val_accuracy: 0.5283 - val_loss: 1.1747\n",
            "Epoch 2/20\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5495 - loss: 1.1212\n",
            "Epoch 2: val_loss improved from 1.17466 to 0.92319, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5497 - loss: 1.1206 - val_accuracy: 0.6357 - val_loss: 0.9232\n",
            "Epoch 3/20\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6513 - loss: 0.8836\n",
            "Epoch 3: val_loss improved from 0.92319 to 0.86906, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6514 - loss: 0.8834 - val_accuracy: 0.6612 - val_loss: 0.8691\n",
            "Epoch 4/20\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7117 - loss: 0.7623\n",
            "Epoch 4: val_loss improved from 0.86906 to 0.79133, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7117 - loss: 0.7621 - val_accuracy: 0.7021 - val_loss: 0.7913\n",
            "Epoch 5/20\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7443 - loss: 0.6813\n",
            "Epoch 5: val_loss improved from 0.79133 to 0.75394, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7443 - loss: 0.6811 - val_accuracy: 0.7164 - val_loss: 0.7539\n",
            "Epoch 6/20\n",
            "\u001b[1m532/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.6060\n",
            "Epoch 6: val_loss did not improve from 0.75394\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7733 - loss: 0.6058 - val_accuracy: 0.7119 - val_loss: 0.7722\n",
            "Epoch 7/20\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7984 - loss: 0.5535\n",
            "Epoch 7: val_loss did not improve from 0.75394\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7985 - loss: 0.5535 - val_accuracy: 0.7247 - val_loss: 0.7606\n",
            "✅ Best fold info saved to best_val_result.json\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "------------------\n",
            "Epoch 1/20\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2900 - loss: 1.5461\n",
            "Epoch 1: val_loss improved from inf to 1.31969, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.2901 - loss: 1.5459 - val_accuracy: 0.4439 - val_loss: 1.3197\n",
            "Epoch 2/20\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4815 - loss: 1.2525\n",
            "Epoch 2: val_loss improved from 1.31969 to 1.05239, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4818 - loss: 1.2519 - val_accuracy: 0.5754 - val_loss: 1.0524\n",
            "Epoch 3/20\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6190 - loss: 0.9645\n",
            "Epoch 3: val_loss improved from 1.05239 to 0.87553, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.6191 - loss: 0.9642 - val_accuracy: 0.6682 - val_loss: 0.8755\n",
            "Epoch 4/20\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6863 - loss: 0.8156\n",
            "Epoch 4: val_loss improved from 0.87553 to 0.81562, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6864 - loss: 0.8153 - val_accuracy: 0.6917 - val_loss: 0.8156\n",
            "Epoch 5/20\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7335 - loss: 0.7095\n",
            "Epoch 5: val_loss improved from 0.81562 to 0.77296, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7336 - loss: 0.7095 - val_accuracy: 0.7090 - val_loss: 0.7730\n",
            "Epoch 6/20\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7690 - loss: 0.6323\n",
            "Epoch 6: val_loss improved from 0.77296 to 0.74646, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7690 - loss: 0.6321 - val_accuracy: 0.7213 - val_loss: 0.7465\n",
            "Epoch 7/20\n",
            "\u001b[1m532/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7943 - loss: 0.5695\n",
            "Epoch 7: val_loss did not improve from 0.74646\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.7943 - loss: 0.5694 - val_accuracy: 0.7136 - val_loss: 0.7847\n",
            "Epoch 8/20\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.5339\n",
            "Epoch 8: val_loss did not improve from 0.74646\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8073 - loss: 0.5338 - val_accuracy: 0.7131 - val_loss: 0.7947\n",
            "✅ Best fold info saved to best_val_result.json\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "------------------\n",
            "Epoch 1/20\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2848 - loss: 1.5516\n",
            "Epoch 1: val_loss improved from inf to 1.30534, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2851 - loss: 1.5513 - val_accuracy: 0.4920 - val_loss: 1.3053\n",
            "Epoch 2/20\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5492 - loss: 1.1598\n",
            "Epoch 2: val_loss improved from 1.30534 to 0.92220, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.5496 - loss: 1.1587 - val_accuracy: 0.6396 - val_loss: 0.9222\n",
            "Epoch 3/20\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6646 - loss: 0.8791\n",
            "Epoch 3: val_loss did not improve from 0.92220\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6648 - loss: 0.8786 - val_accuracy: 0.6498 - val_loss: 0.9544\n",
            "Epoch 4/20\n",
            "\u001b[1m534/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 0.7556\n",
            "Epoch 4: val_loss improved from 0.92220 to 0.91325, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7223 - loss: 0.7552 - val_accuracy: 0.6709 - val_loss: 0.9133\n",
            "Epoch 5/20\n",
            "\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7609 - loss: 0.6541\n",
            "Epoch 5: val_loss improved from 0.91325 to 0.86183, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7610 - loss: 0.6541 - val_accuracy: 0.6917 - val_loss: 0.8618\n",
            "Epoch 6/20\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7916 - loss: 0.5889\n",
            "Epoch 6: val_loss improved from 0.86183 to 0.76575, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7916 - loss: 0.5889 - val_accuracy: 0.7180 - val_loss: 0.7658\n",
            "Epoch 7/20\n",
            "\u001b[1m539/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8042 - loss: 0.5505\n",
            "Epoch 7: val_loss improved from 0.76575 to 0.76349, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8043 - loss: 0.5505 - val_accuracy: 0.7250 - val_loss: 0.7635\n",
            "Epoch 8/20\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8258 - loss: 0.5020\n",
            "Epoch 8: val_loss did not improve from 0.76349\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8258 - loss: 0.5019 - val_accuracy: 0.7265 - val_loss: 0.7761\n",
            "Epoch 9/20\n",
            "\u001b[1m532/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 0.4659\n",
            "Epoch 9: val_loss did not improve from 0.76349\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8402 - loss: 0.4660 - val_accuracy: 0.7207 - val_loss: 0.8242\n",
            "✅ Best fold info saved to best_val_result.json\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "------------------\n",
            "Epoch 1/20\n",
            "\u001b[1m538/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2968 - loss: 1.5519\n",
            "Epoch 1: val_loss improved from inf to 1.18990, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2973 - loss: 1.5513 - val_accuracy: 0.5515 - val_loss: 1.1899\n",
            "Epoch 2/20\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5563 - loss: 1.1277\n",
            "Epoch 2: val_loss improved from 1.18990 to 0.94320, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5566 - loss: 1.1268 - val_accuracy: 0.6373 - val_loss: 0.9432\n",
            "Epoch 3/20\n",
            "\u001b[1m536/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6540 - loss: 0.9015\n",
            "Epoch 3: val_loss improved from 0.94320 to 0.88905, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6541 - loss: 0.9012 - val_accuracy: 0.6573 - val_loss: 0.8891\n",
            "Epoch 4/20\n",
            "\u001b[1m531/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7011 - loss: 0.7912\n",
            "Epoch 4: val_loss improved from 0.88905 to 0.77622, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7014 - loss: 0.7906 - val_accuracy: 0.7118 - val_loss: 0.7762\n",
            "Epoch 5/20\n",
            "\u001b[1m537/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7425 - loss: 0.6886\n",
            "Epoch 5: val_loss improved from 0.77622 to 0.73733, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7426 - loss: 0.6883 - val_accuracy: 0.7286 - val_loss: 0.7373\n",
            "Epoch 6/20\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7802 - loss: 0.5993\n",
            "Epoch 6: val_loss improved from 0.73733 to 0.70763, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7803 - loss: 0.5992 - val_accuracy: 0.7407 - val_loss: 0.7076\n",
            "Epoch 7/20\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8066 - loss: 0.5465\n",
            "Epoch 7: val_loss did not improve from 0.70763\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8067 - loss: 0.5462 - val_accuracy: 0.7443 - val_loss: 0.7126\n",
            "Epoch 8/20\n",
            "\u001b[1m533/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8068 - loss: 0.5377\n",
            "Epoch 8: val_loss did not improve from 0.70763\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8070 - loss: 0.5371 - val_accuracy: 0.7191 - val_loss: 0.8054\n",
            "✅ Best fold info saved to best_val_result.json\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 확인 (nn_feat2 만)\n",
        "with open('best_val_result.json', 'r') as f:\n",
        "    result = json.load(f)\n",
        "\n",
        "print(f\"Best fold: {result['fold']}, val_loss: {result['val_loss']}, val_accuracy: {result['val_accuracy']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gZ2Kz2AxhxJ",
        "outputId": "8824688b-3561-49f3-d335-fd50e98048c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best fold: 6, val_loss: 0.8095, val_accuracy: 0.714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nn으로 생성한 피처 csv 파일로 저장\n",
        "pd.DataFrame(nn_train1).to_csv('nn_train1.csv', index=False)\n",
        "pd.DataFrame(nn_test1).to_csv('nn_test1.csv', index=False)\n",
        "pd.DataFrame(nn_train2).to_csv('nn_train2.csv', index=False)\n",
        "pd.DataFrame(nn_test2).to_csv('nn_test2.csv', index=False)"
      ],
      "metadata": {
        "id": "8o6zwuB3WcuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잘 저장되었는지 확인\n",
        "chk = pd.read_csv('/content/nn_test1.csv')\n",
        "chk.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "71dx-qA9W0IJ",
        "outputId": "bc278e1b-b0ab-4dfe-858d-48b6ab5d1b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4\n",
              "0  0.000194  0.915968  0.067935  0.015842  0.000061\n",
              "1  0.342317  0.425324  0.145968  0.034048  0.052343\n",
              "2  0.941147  0.014920  0.001230  0.000218  0.042485\n",
              "3  0.000006  0.000039  0.969542  0.000013  0.030399\n",
              "4  0.992519  0.002278  0.000037  0.004370  0.000795"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abf013bd-8c68-42ed-b2e4-44751068fc8b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.915968</td>\n",
              "      <td>0.067935</td>\n",
              "      <td>0.015842</td>\n",
              "      <td>0.000061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.342317</td>\n",
              "      <td>0.425324</td>\n",
              "      <td>0.145968</td>\n",
              "      <td>0.034048</td>\n",
              "      <td>0.052343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.941147</td>\n",
              "      <td>0.014920</td>\n",
              "      <td>0.001230</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>0.042485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.969542</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.030399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.992519</td>\n",
              "      <td>0.002278</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.004370</td>\n",
              "      <td>0.000795</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abf013bd-8c68-42ed-b2e4-44751068fc8b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-abf013bd-8c68-42ed-b2e4-44751068fc8b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-abf013bd-8c68-42ed-b2e4-44751068fc8b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-28ec8ce2-feb4-41e8-afaf-fa123fe2164e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-28ec8ce2-feb4-41e8-afaf-fa123fe2164e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-28ec8ce2-feb4-41e8-afaf-fa123fe2164e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "chk",
              "summary": "{\n  \"name\": \"chk\",\n  \"rows\": 19617,\n  \"fields\": [\n    {\n      \"column\": \"0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3649673737399495,\n        \"min\": 2.795746014870272e-13,\n        \"max\": 0.9999999031424522,\n        \"num_unique_values\": 19600,\n        \"samples\": [\n          0.0138747310556937,\n          0.0329865351668559,\n          0.0016439144419564\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36223639265183905,\n        \"min\": 2.1666955223036197e-15,\n        \"max\": 0.999999925494194,\n        \"num_unique_values\": 19506,\n        \"samples\": [\n          0.0028120225970269,\n          0.978710137307644,\n          0.0001808530753351\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34773412983388313,\n        \"min\": 2.577319388889727e-13,\n        \"max\": 0.9999338686466216,\n        \"num_unique_values\": 19596,\n        \"samples\": [\n          7.224001535721669e-05,\n          0.172510715201497,\n          0.9985064417123796\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4010532116254104,\n        \"min\": 3.6866946125901304e-14,\n        \"max\": 0.9999999403953552,\n        \"num_unique_values\": 19365,\n        \"samples\": [\n          2.002234166198491e-05,\n          3.20316503703566e-05,\n          0.8920757845044136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2618433970274363,\n        \"min\": 5.590974756438205e-15,\n        \"max\": 0.9999801069498062,\n        \"num_unique_values\": 19603,\n        \"samples\": [\n          0.2740090365987271,\n          0.453344190493226,\n          0.9617223218083382\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CNN으로 피처 생성**"
      ],
      "metadata": {
        "id": "MK8Js3MMx6IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cnn_feats(rnd=1):\n",
        "    train_pred, test_pred = np.zeros((54879, 5)), np.zeros((19617, 5))\n",
        "    best_val_train_pred, best_val_test_pred = np.zeros((54879, 5)), np.zeros((19617, 5))\n",
        "\n",
        "    FEAT_CNT = 5\n",
        "    NUM_WORDS = 16000\n",
        "    EMBED_DIM = 64\n",
        "    MAX_LEN = 300\n",
        "    NUM_CLASSES = 5\n",
        "    MODEL_P = 'cnn_model.h5'\n",
        "\n",
        "    tmp_X = train['text']\n",
        "    tmp_Y = train['author']\n",
        "    tmp_X_test = test['text']\n",
        "\n",
        "    # Tokenizing\n",
        "    tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
        "    tokenizer.fit_on_texts(tmp_X)\n",
        "    ttrain_x = tokenizer.texts_to_sequences(tmp_X)\n",
        "    ttrain_x = pad_sequences(ttrain_x, maxlen=MAX_LEN)\n",
        "    ttest_x = tokenizer.texts_to_sequences(tmp_X_test)\n",
        "    ttest_x = pad_sequences(ttest_x, maxlen=MAX_LEN)\n",
        "\n",
        "    # Label one-hot encoding\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    lb.fit(tmp_Y)\n",
        "    ttrain_y = lb.transform(tmp_Y)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=FEAT_CNT, shuffle=True, random_state=2333 * rnd)\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(ttrain_x, tmp_Y)):\n",
        "        print(f\"🌊 Fold {fold+1}/{FEAT_CNT}\")\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(NUM_WORDS, EMBED_DIM, input_length=MAX_LEN))\n",
        "        model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "        model.add(GlobalMaxPooling1D())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "        mc = ModelCheckpoint(filepath=MODEL_P, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "        es = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "        np.random.seed(42)\n",
        "        model.fit(\n",
        "            ttrain_x[train_index], ttrain_y[train_index],\n",
        "            validation_split=0.1,\n",
        "            batch_size=256, epochs=10,\n",
        "            verbose=1,\n",
        "            callbacks=[mc, es],\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        # feature 생성 1 (현재 모델)\n",
        "        train_pred[val_index] = model.predict(ttrain_x[val_index])\n",
        "        test_pred += model.predict(ttest_x) / FEAT_CNT\n",
        "\n",
        "        # feature 생성 2 (best 모델)\n",
        "        model = load_model(MODEL_P)\n",
        "        best_val_train_pred[val_index] = model.predict(ttrain_x[val_index])\n",
        "        best_val_test_pred += model.predict(ttest_x) / FEAT_CNT\n",
        "\n",
        "        del model\n",
        "        gc.collect()\n",
        "        print('------------------')\n",
        "\n",
        "    return train_pred, test_pred, best_val_train_pred, best_val_test_pred\n"
      ],
      "metadata": {
        "id": "b17dPfBSXRKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_train1, cnn_test1, cnn_train2, cnn_test2 = get_cnn_feats(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFvy4MrMPIYX",
        "outputId": "8153afff-c041-456e-8a79-e0b0b7436eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌊 Fold 1/5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.3560 - loss: 1.4667\n",
            "Epoch 1: val_loss improved from inf to 0.92947, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 598ms/step - accuracy: 0.3567 - loss: 1.4656 - val_accuracy: 0.6402 - val_loss: 0.9295\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554ms/step - accuracy: 0.6896 - loss: 0.8258\n",
            "Epoch 2: val_loss improved from 0.92947 to 0.68358, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 588ms/step - accuracy: 0.6899 - loss: 0.8251 - val_accuracy: 0.7511 - val_loss: 0.6836\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545ms/step - accuracy: 0.8263 - loss: 0.5030\n",
            "Epoch 3: val_loss improved from 0.68358 to 0.65290, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 562ms/step - accuracy: 0.8265 - loss: 0.5027 - val_accuracy: 0.7673 - val_loss: 0.6529\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548ms/step - accuracy: 0.8926 - loss: 0.3258\n",
            "Epoch 4: val_loss did not improve from 0.65290\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 562ms/step - accuracy: 0.8926 - loss: 0.3256 - val_accuracy: 0.7716 - val_loss: 0.6894\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9278 - loss: 0.2213\n",
            "Epoch 5: val_loss did not improve from 0.65290\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 625ms/step - accuracy: 0.9279 - loss: 0.2212 - val_accuracy: 0.7606 - val_loss: 0.7807\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step\n",
            "------------------\n",
            "🌊 Fold 2/5\n",
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557ms/step - accuracy: 0.3596 - loss: 1.4621\n",
            "Epoch 1: val_loss improved from inf to 0.94023, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 593ms/step - accuracy: 0.3603 - loss: 1.4609 - val_accuracy: 0.6329 - val_loss: 0.9402\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - accuracy: 0.6911 - loss: 0.8220\n",
            "Epoch 2: val_loss improved from 0.94023 to 0.68742, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 595ms/step - accuracy: 0.6914 - loss: 0.8214 - val_accuracy: 0.7424 - val_loss: 0.6874\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.8259 - loss: 0.4985\n",
            "Epoch 3: val_loss improved from 0.68742 to 0.65476, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 590ms/step - accuracy: 0.8260 - loss: 0.4981 - val_accuracy: 0.7716 - val_loss: 0.6548\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - accuracy: 0.8913 - loss: 0.3253\n",
            "Epoch 4: val_loss did not improve from 0.65476\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 591ms/step - accuracy: 0.8914 - loss: 0.3251 - val_accuracy: 0.7770 - val_loss: 0.6844\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step - accuracy: 0.9294 - loss: 0.2181\n",
            "Epoch 5: val_loss did not improve from 0.65476\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 545ms/step - accuracy: 0.9294 - loss: 0.2180 - val_accuracy: 0.7732 - val_loss: 0.7497\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step\n",
            "------------------\n",
            "🌊 Fold 3/5\n",
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.3675 - loss: 1.4606\n",
            "Epoch 1: val_loss improved from inf to 0.91199, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 587ms/step - accuracy: 0.3682 - loss: 1.4594 - val_accuracy: 0.6509 - val_loss: 0.9120\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581ms/step - accuracy: 0.7058 - loss: 0.7969\n",
            "Epoch 2: val_loss improved from 0.91199 to 0.67330, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 596ms/step - accuracy: 0.7060 - loss: 0.7963 - val_accuracy: 0.7518 - val_loss: 0.6733\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.8306 - loss: 0.4842\n",
            "Epoch 3: val_loss improved from 0.67330 to 0.64525, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 580ms/step - accuracy: 0.8308 - loss: 0.4839 - val_accuracy: 0.7700 - val_loss: 0.6453\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.8979 - loss: 0.3122\n",
            "Epoch 4: val_loss did not improve from 0.64525\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 597ms/step - accuracy: 0.8980 - loss: 0.3121 - val_accuracy: 0.7677 - val_loss: 0.7000\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - accuracy: 0.9338 - loss: 0.2103\n",
            "Epoch 5: val_loss did not improve from 0.64525\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 566ms/step - accuracy: 0.9338 - loss: 0.2101 - val_accuracy: 0.7602 - val_loss: 0.7677\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step\n",
            "------------------\n",
            "🌊 Fold 4/5\n",
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571ms/step - accuracy: 0.3578 - loss: 1.4677\n",
            "Epoch 1: val_loss improved from inf to 0.94892, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 590ms/step - accuracy: 0.3584 - loss: 1.4666 - val_accuracy: 0.6327 - val_loss: 0.9489\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - accuracy: 0.6903 - loss: 0.8244\n",
            "Epoch 2: val_loss improved from 0.94892 to 0.68532, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 590ms/step - accuracy: 0.6905 - loss: 0.8237 - val_accuracy: 0.7474 - val_loss: 0.6853\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step - accuracy: 0.8282 - loss: 0.4919\n",
            "Epoch 3: val_loss improved from 0.68532 to 0.65303, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 620ms/step - accuracy: 0.8283 - loss: 0.4915 - val_accuracy: 0.7750 - val_loss: 0.6530\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - accuracy: 0.8969 - loss: 0.3134\n",
            "Epoch 4: val_loss did not improve from 0.65303\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 570ms/step - accuracy: 0.8970 - loss: 0.3132 - val_accuracy: 0.7711 - val_loss: 0.7035\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - accuracy: 0.9330 - loss: 0.2104\n",
            "Epoch 5: val_loss did not improve from 0.65303\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 575ms/step - accuracy: 0.9331 - loss: 0.2103 - val_accuracy: 0.7679 - val_loss: 0.7661\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step\n",
            "------------------\n",
            "🌊 Fold 5/5\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529ms/step - accuracy: 0.3523 - loss: 1.4744\n",
            "Epoch 1: val_loss improved from inf to 0.95215, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 548ms/step - accuracy: 0.3530 - loss: 1.4733 - val_accuracy: 0.6263 - val_loss: 0.9522\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step - accuracy: 0.6812 - loss: 0.8416\n",
            "Epoch 2: val_loss improved from 0.95215 to 0.67154, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 573ms/step - accuracy: 0.6815 - loss: 0.8409 - val_accuracy: 0.7563 - val_loss: 0.6715\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.8231 - loss: 0.5109\n",
            "Epoch 3: val_loss improved from 0.67154 to 0.64155, saving model to cnn_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 587ms/step - accuracy: 0.8232 - loss: 0.5105 - val_accuracy: 0.7716 - val_loss: 0.6415\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.8886 - loss: 0.3366\n",
            "Epoch 4: val_loss did not improve from 0.64155\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 563ms/step - accuracy: 0.8887 - loss: 0.3363 - val_accuracy: 0.7682 - val_loss: 0.6860\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554ms/step - accuracy: 0.9268 - loss: 0.2281\n",
            "Epoch 5: val_loss did not improve from 0.64155\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 570ms/step - accuracy: 0.9269 - loss: 0.2280 - val_accuracy: 0.7700 - val_loss: 0.7277\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step\n",
            "------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_cnn_feats_to_csv(cnn_train1, cnn_test1, cnn_train2, cnn_test2, base_filename=\"cnn_features\"):\n",
        "    \"\"\"\n",
        "    get_cnn_feats 함수에서 얻은 NumPy 배열들을 각각 CSV 파일로 저장합니다.\n",
        "\n",
        "    Args:\n",
        "        cnn_train1, cnn_test1, cnn_train2, cnn_test2 (np.ndarray): 메타 피처들\n",
        "        base_filename (str): 저장 파일 이름의 prefix (기본값: 'nn_features')\n",
        "    \"\"\"\n",
        "\n",
        "# cnn으로 생성한 피처 csv 파일로 저장\n",
        "pd.DataFrame(cnn_train1).to_csv('cnn_train1.csv', index=False)\n",
        "pd.DataFrame(cnn_test1).to_csv('cnn_test1.csv', index=False)\n",
        "pd.DataFrame(cnn_train2).to_csv('cnn_train2.csv', index=False)\n",
        "pd.DataFrame(cnn_test2).to_csv('cnn_test2.csv', index=False)"
      ],
      "metadata": {
        "id": "9x5EXKw2Pfkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GRU로 피처 생성**"
      ],
      "metadata": {
        "id": "DETZLh_gxjOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import GRU"
      ],
      "metadata": {
        "id": "OQvdW0eHMRVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gru_feats(rnd=1):\n",
        "    train_pred, test_pred = np.zeros((54879,5)),np.zeros((19617,5))\n",
        "    best_val_train_pred, best_val_test_pred = np.zeros((54879,5)),np.zeros((19617,5))\n",
        "    FEAT_CNT = 5\n",
        "    NUM_WORDS = 16000\n",
        "    N = 12\n",
        "    MAX_LEN = 300\n",
        "    NUM_CLASSES = 5\n",
        "    MODEL_P = 'nn_model.h5'\n",
        "\n",
        "    tmp_X = train['text']\n",
        "    tmp_Y = train['author']\n",
        "    tmp_X_test = test['text']\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
        "    tokenizer.fit_on_texts(tmp_X)\n",
        "\n",
        "    ttrain_x = tokenizer.texts_to_sequences(tmp_X)\n",
        "    ttrain_x = pad_sequences(ttrain_x, maxlen=MAX_LEN)\n",
        "\n",
        "    ttest_x = tokenizer.texts_to_sequences(tmp_X_test)\n",
        "    ttest_x = pad_sequences(ttest_x, maxlen=MAX_LEN)\n",
        "\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    lb.fit(tmp_Y)\n",
        "\n",
        "    ttrain_y = lb.transform(tmp_Y)\n",
        "    skf = StratifiedKFold(n_splits=FEAT_CNT, shuffle=True, random_state=2333*rnd)\n",
        "    for train_index, test_index in skf.split(ttrain_x,tmp_Y):\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(NUM_WORDS, N, input_length=MAX_LEN))\n",
        "        model.add(GRU(N, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "        mc = ModelCheckpoint(filepath=MODEL_P, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "        es=EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "        np.random.seed(42)\n",
        "        model.fit(ttrain_x[train_index], ttrain_y[train_index],\n",
        "                  validation_split=0.1,\n",
        "                  batch_size=256, epochs=10,\n",
        "                  verbose=1,\n",
        "                  callbacks=[mc,es],\n",
        "                  shuffle=False\n",
        "                 )\n",
        "\n",
        "        # feature 생성 1\n",
        "        train_pred[test_index] = model.predict(ttrain_x[test_index])\n",
        "        test_pred += model.predict(ttest_x)/FEAT_CNT\n",
        "\n",
        "        # feature 생성 2\n",
        "        model = load_model(MODEL_P)\n",
        "        best_val_train_pred[test_index] = model.predict(ttrain_x[test_index])\n",
        "        best_val_test_pred += model.predict(ttest_x)/FEAT_CNT\n",
        "\n",
        "        del model\n",
        "        gc.collect()\n",
        "        print('------------------')\n",
        "\n",
        "    return train_pred,test_pred,best_val_train_pred,best_val_test_pred"
      ],
      "metadata": {
        "id": "bJoMwhqBL6Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_train1,gru_test1,gru_train2,gru_test2 = get_gru_feats(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-6wQ5qZMdNO",
        "outputId": "d808b28c-f686-4fb8-f1db-f5975fd259cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.3427 - loss: 1.4745\n",
            "Epoch 1: val_loss improved from inf to 1.02439, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 305ms/step - accuracy: 0.3433 - loss: 1.4734 - val_accuracy: 0.5862 - val_loss: 1.0244\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.6275 - loss: 0.9471\n",
            "Epoch 2: val_loss improved from 1.02439 to 0.79951, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 311ms/step - accuracy: 0.6277 - loss: 0.9467 - val_accuracy: 0.6967 - val_loss: 0.7995\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.7338 - loss: 0.7096\n",
            "Epoch 3: val_loss improved from 0.79951 to 0.74352, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.7339 - loss: 0.7094 - val_accuracy: 0.7185 - val_loss: 0.7435\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.7853 - loss: 0.5833\n",
            "Epoch 4: val_loss improved from 0.74352 to 0.72682, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.7854 - loss: 0.5831 - val_accuracy: 0.7244 - val_loss: 0.7268\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8228 - loss: 0.4917\n",
            "Epoch 5: val_loss did not improve from 0.72682\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 320ms/step - accuracy: 0.8228 - loss: 0.4916 - val_accuracy: 0.7294 - val_loss: 0.7645\n",
            "Epoch 6/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.8429 - loss: 0.4378\n",
            "Epoch 6: val_loss did not improve from 0.72682\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 301ms/step - accuracy: 0.8429 - loss: 0.4377 - val_accuracy: 0.7331 - val_loss: 0.7696\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 44ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 38ms/step\n",
            "------------------\n",
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.3424 - loss: 1.4905\n",
            "Epoch 1: val_loss improved from inf to 1.04844, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 305ms/step - accuracy: 0.3430 - loss: 1.4896 - val_accuracy: 0.5798 - val_loss: 1.0484\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.6127 - loss: 0.9763\n",
            "Epoch 2: val_loss improved from 1.04844 to 0.84767, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 326ms/step - accuracy: 0.6129 - loss: 0.9759 - val_accuracy: 0.6707 - val_loss: 0.8477\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.7194 - loss: 0.7392\n",
            "Epoch 3: val_loss improved from 0.84767 to 0.76516, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 309ms/step - accuracy: 0.7196 - loss: 0.7389 - val_accuracy: 0.7083 - val_loss: 0.7652\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.7815 - loss: 0.5881\n",
            "Epoch 4: val_loss improved from 0.76516 to 0.74391, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 322ms/step - accuracy: 0.7816 - loss: 0.5879 - val_accuracy: 0.7192 - val_loss: 0.7439\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.8214 - loss: 0.4908\n",
            "Epoch 5: val_loss did not improve from 0.74391\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 314ms/step - accuracy: 0.8215 - loss: 0.4906 - val_accuracy: 0.7335 - val_loss: 0.7524\n",
            "Epoch 6/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.8509 - loss: 0.4211\n",
            "Epoch 6: val_loss did not improve from 0.74391\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 320ms/step - accuracy: 0.8509 - loss: 0.4211 - val_accuracy: 0.7345 - val_loss: 0.7956\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 38ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step\n",
            "------------------\n",
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.3480 - loss: 1.4869\n",
            "Epoch 1: val_loss improved from inf to 1.02099, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 314ms/step - accuracy: 0.3486 - loss: 1.4859 - val_accuracy: 0.6001 - val_loss: 1.0210\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.6237 - loss: 0.9623\n",
            "Epoch 2: val_loss improved from 1.02099 to 0.81779, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 312ms/step - accuracy: 0.6239 - loss: 0.9619 - val_accuracy: 0.6809 - val_loss: 0.8178\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.7197 - loss: 0.7364\n",
            "Epoch 3: val_loss improved from 0.81779 to 0.73659, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.7198 - loss: 0.7361 - val_accuracy: 0.7140 - val_loss: 0.7366\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.7827 - loss: 0.5877\n",
            "Epoch 4: val_loss improved from 0.73659 to 0.73509, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.7827 - loss: 0.5876 - val_accuracy: 0.7283 - val_loss: 0.7351\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.8198 - loss: 0.4951\n",
            "Epoch 5: val_loss improved from 0.73509 to 0.70752, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 302ms/step - accuracy: 0.8198 - loss: 0.4950 - val_accuracy: 0.7429 - val_loss: 0.7075\n",
            "Epoch 6/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.8487 - loss: 0.4186\n",
            "Epoch 6: val_loss did not improve from 0.70752\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 301ms/step - accuracy: 0.8487 - loss: 0.4185 - val_accuracy: 0.7502 - val_loss: 0.7184\n",
            "Epoch 7/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8672 - loss: 0.3760\n",
            "Epoch 7: val_loss did not improve from 0.70752\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 313ms/step - accuracy: 0.8672 - loss: 0.3759 - val_accuracy: 0.7522 - val_loss: 0.7448\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 38ms/step\n",
            "------------------\n",
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.3433 - loss: 1.4881\n",
            "Epoch 1: val_loss improved from inf to 1.03435, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 320ms/step - accuracy: 0.3438 - loss: 1.4872 - val_accuracy: 0.5958 - val_loss: 1.0343\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.6245 - loss: 0.9642\n",
            "Epoch 2: val_loss improved from 1.03435 to 0.80153, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.6247 - loss: 0.9637 - val_accuracy: 0.6946 - val_loss: 0.8015\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.7334 - loss: 0.7102\n",
            "Epoch 3: val_loss improved from 0.80153 to 0.73840, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.7335 - loss: 0.7099 - val_accuracy: 0.7156 - val_loss: 0.7384\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.7870 - loss: 0.5776\n",
            "Epoch 4: val_loss improved from 0.73840 to 0.72576, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.7871 - loss: 0.5774 - val_accuracy: 0.7310 - val_loss: 0.7258\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.8187 - loss: 0.4968\n",
            "Epoch 5: val_loss did not improve from 0.72576\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 300ms/step - accuracy: 0.8188 - loss: 0.4968 - val_accuracy: 0.7324 - val_loss: 0.7431\n",
            "Epoch 6/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.8434 - loss: 0.4403\n",
            "Epoch 6: val_loss did not improve from 0.72576\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 309ms/step - accuracy: 0.8434 - loss: 0.4402 - val_accuracy: 0.7274 - val_loss: 0.7958\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 40ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 38ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step\n",
            "------------------\n",
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.3437 - loss: 1.4855\n",
            "Epoch 1: val_loss improved from inf to 1.05287, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 318ms/step - accuracy: 0.3444 - loss: 1.4845 - val_accuracy: 0.5762 - val_loss: 1.0529\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.6129 - loss: 0.9768\n",
            "Epoch 2: val_loss improved from 1.05287 to 0.86542, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 305ms/step - accuracy: 0.6131 - loss: 0.9763 - val_accuracy: 0.6607 - val_loss: 0.8654\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.7183 - loss: 0.7471\n",
            "Epoch 3: val_loss improved from 0.86542 to 0.74883, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.7185 - loss: 0.7468 - val_accuracy: 0.7153 - val_loss: 0.7488\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.7783 - loss: 0.5955\n",
            "Epoch 4: val_loss improved from 0.74883 to 0.72383, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 318ms/step - accuracy: 0.7784 - loss: 0.5954 - val_accuracy: 0.7326 - val_loss: 0.7238\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.8135 - loss: 0.5088\n",
            "Epoch 5: val_loss did not improve from 0.72383\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 302ms/step - accuracy: 0.8136 - loss: 0.5087 - val_accuracy: 0.7324 - val_loss: 0.7405\n",
            "Epoch 6/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8405 - loss: 0.4451\n",
            "Epoch 6: val_loss did not improve from 0.72383\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 318ms/step - accuracy: 0.8406 - loss: 0.4450 - val_accuracy: 0.7383 - val_loss: 0.7659\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step\n",
            "------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def save_gru_feats_to_csv(gru_train1, gru_test1, gru_train2, gru_test2, base_filename=\"gru_features\"):\n",
        "    \"\"\"\n",
        "    get_gru_feats 함수에서 얻은 NumPy 배열들을 각각 CSV 파일로 저장합니다.\n",
        "\n",
        "    Args:\n",
        "        gru_train1 (numpy.ndarray): 첫 번째 GRU 학습 데이터 특징 배열.\n",
        "        gru_test1 (numpy.ndarray): 첫 번째 GRU 테스트 데이터 특징 배열.\n",
        "        gru_train2 (numpy.ndarray): 두 번째 GRU 학습 데이터 특징 배열.\n",
        "        gru_test2 (numpy.ndarray): 두 번째 GRU 테스트 데이터 특징 배열.\n",
        "        base_filename (str, optional): 저장될 파일명의 기본 이름. Defaults to \"gru_features\".\n",
        "    \"\"\"\n",
        "    # gru_train1을 DataFrame으로 변환하고 CSV 파일로 저장\n",
        "    df_train1 = pd.DataFrame(gru_train1)\n",
        "    train1_filename = f\"{base_filename}_train1.csv\"\n",
        "    df_train1.to_csv(train1_filename, index=False)\n",
        "    print(f\"'{train1_filename}' 파일로 저장 완료.\")\n",
        "\n",
        "    # gru_test1을 DataFrame으로 변환하고 CSV 파일로 저장\n",
        "    df_test1 = pd.DataFrame(gru_test1)\n",
        "    test1_filename = f\"{base_filename}_test1.csv\"\n",
        "    df_test1.to_csv(test1_filename, index=False)\n",
        "    print(f\"'{test1_filename}' 파일로 저장 완료.\")\n",
        "\n",
        "    # gru_train2를 DataFrame으로 변환하고 CSV 파일로 저장\n",
        "    df_train2 = pd.DataFrame(gru_train2)\n",
        "    train2_filename = f\"{base_filename}_train2.csv\"\n",
        "    df_train2.to_csv(train2_filename, index=False)\n",
        "    print(f\"'{train2_filename}' 파일로 저장 완료.\")\n",
        "\n",
        "    # gru_test2를 DataFrame으로 변환하고 CSV 파일로 저장\n",
        "    df_test2 = pd.DataFrame(gru_test2)\n",
        "    test2_filename = f\"{base_filename}_test2.csv\"\n",
        "    df_test2.to_csv(test2_filename, index=False)\n",
        "    print(f\"'{test2_filename}' 파일로 저장 완료.\")\n",
        "\n",
        "# CSV 파일로 저장하는 함수를 호출합니다.\n",
        "save_gru_feats_to_csv(gru_train1, gru_test1, gru_train2, gru_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEzm_LpIvvGL",
        "outputId": "75ac2544-cc85-4ab7-82b0-ab6924928842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'gru_features_train1.csv' 파일로 저장 완료.\n",
            "'gru_features_test1.csv' 파일로 저장 완료.\n",
            "'gru_features_train2.csv' 파일로 저장 완료.\n",
            "'gru_features_test2.csv' 파일로 저장 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM으로 피처 생성**"
      ],
      "metadata": {
        "id": "SNFLORhIx7wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gc\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model, Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.layers import Flatten"
      ],
      "metadata": {
        "id": "yD5Ub8JITPV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lstm_feats(rnd=1):\n",
        "    train_pred, test_pred = np.zeros((54879,5)),np.zeros((19617,5))\n",
        "    best_val_train_pred, best_val_test_pred = np.zeros((54879,5)),np.zeros((19617,5))\n",
        "    FEAT_CNT = 5\n",
        "    NUM_WORDS = 16000\n",
        "    N = 12\n",
        "    MAX_LEN = 300\n",
        "    NUM_CLASSES = 5\n",
        "    MODEL_P = 'nn_model.h5'\n",
        "\n",
        "    tmp_X = train['text']\n",
        "    tmp_Y = train['author']\n",
        "    tmp_X_test = test['text']\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
        "    tokenizer.fit_on_texts(tmp_X)\n",
        "\n",
        "    ttrain_x = tokenizer.texts_to_sequences(tmp_X)\n",
        "    ttrain_x = pad_sequences(ttrain_x, maxlen=MAX_LEN)\n",
        "\n",
        "    ttest_x = tokenizer.texts_to_sequences(tmp_X_test)\n",
        "    ttest_x = pad_sequences(ttest_x, maxlen=MAX_LEN)\n",
        "\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    lb.fit(tmp_Y)\n",
        "\n",
        "    ttrain_y = lb.transform(tmp_Y)\n",
        "    skf = StratifiedKFold(n_splits=FEAT_CNT, shuffle=True, random_state=2333*rnd)\n",
        "    for train_index, test_index in skf.split(ttrain_x,tmp_Y):\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(NUM_WORDS, N, input_length=MAX_LEN))\n",
        "        model.add(LSTM(N, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "        mc = ModelCheckpoint(filepath=MODEL_P, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "        es=EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "        np.random.seed(42)\n",
        "        model.fit(ttrain_x[train_index], ttrain_y[train_index],\n",
        "                  validation_split=0.1,\n",
        "                  batch_size=256, epochs=10,\n",
        "                  verbose=1,\n",
        "                  callbacks=[mc,es],\n",
        "                  shuffle=False\n",
        "                 )\n",
        "\n",
        "        # feature 생성 1\n",
        "        train_pred[test_index] = model.predict(ttrain_x[test_index])\n",
        "        test_pred += model.predict(ttest_x)/FEAT_CNT\n",
        "\n",
        "        # feature 생성 2\n",
        "        model = load_model(MODEL_P)\n",
        "        best_val_train_pred[test_index] = model.predict(ttrain_x[test_index])\n",
        "        best_val_test_pred += model.predict(ttest_x)/FEAT_CNT\n",
        "\n",
        "        del model\n",
        "        gc.collect()\n",
        "        print('------------------')\n",
        "\n",
        "    return train_pred,test_pred,best_val_train_pred,best_val_test_pred"
      ],
      "metadata": {
        "id": "gsidoUw-ybII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_train1,lstm_test1,lstm_train2,lstm_test2 = get_lstm_feats(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEUITnY0TZDR",
        "outputId": "1a111a38-0044-420a-9ead-e3b95b9575ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.3217 - loss: 1.5062\n",
            "Epoch 1: val_loss improved from inf to 1.05573, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.3223 - loss: 1.5054 - val_accuracy: 0.5958 - val_loss: 1.0557\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.5997 - loss: 1.0197\n",
            "Epoch 2: val_loss improved from 1.05573 to 0.82943, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 357ms/step - accuracy: 0.5999 - loss: 1.0193 - val_accuracy: 0.6812 - val_loss: 0.8294\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.7161 - loss: 0.7515\n",
            "Epoch 3: val_loss improved from 0.82943 to 0.71616, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 358ms/step - accuracy: 0.7162 - loss: 0.7512 - val_accuracy: 0.7304 - val_loss: 0.7162\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.7874 - loss: 0.5877\n",
            "Epoch 4: val_loss did not improve from 0.71616\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 369ms/step - accuracy: 0.7875 - loss: 0.5876 - val_accuracy: 0.7238 - val_loss: 0.7283\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.8277 - loss: 0.4843\n",
            "Epoch 5: val_loss improved from 0.71616 to 0.68854, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 361ms/step - accuracy: 0.8278 - loss: 0.4841 - val_accuracy: 0.7493 - val_loss: 0.6885\n",
            "Epoch 6/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.8526 - loss: 0.4143\n",
            "Epoch 6: val_loss did not improve from 0.68854\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 366ms/step - accuracy: 0.8527 - loss: 0.4142 - val_accuracy: 0.7556 - val_loss: 0.7162\n",
            "Epoch 7/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.8706 - loss: 0.3642\n",
            "Epoch 7: val_loss did not improve from 0.68854\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 370ms/step - accuracy: 0.8706 - loss: 0.3641 - val_accuracy: 0.7449 - val_loss: 0.7951\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step\n",
            "------------------\n",
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.3291 - loss: 1.4939\n",
            "Epoch 1: val_loss improved from inf to 1.02663, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.3298 - loss: 1.4929 - val_accuracy: 0.5930 - val_loss: 1.0266\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.6208 - loss: 0.9611\n",
            "Epoch 2: val_loss improved from 1.02663 to 0.84276, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 350ms/step - accuracy: 0.6210 - loss: 0.9606 - val_accuracy: 0.6645 - val_loss: 0.8428\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.7213 - loss: 0.7344\n",
            "Epoch 3: val_loss improved from 0.84276 to 0.78109, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 346ms/step - accuracy: 0.7214 - loss: 0.7341 - val_accuracy: 0.7026 - val_loss: 0.7811\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.7734 - loss: 0.6051\n",
            "Epoch 4: val_loss did not improve from 0.78109\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 363ms/step - accuracy: 0.7735 - loss: 0.6050 - val_accuracy: 0.7078 - val_loss: 0.7834\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - accuracy: 0.8079 - loss: 0.5239\n",
            "Epoch 5: val_loss did not improve from 0.78109\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 347ms/step - accuracy: 0.8079 - loss: 0.5238 - val_accuracy: 0.7140 - val_loss: 0.8025\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step\n",
            "------------------\n",
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.3334 - loss: 1.4997\n",
            "Epoch 1: val_loss improved from inf to 1.11499, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 371ms/step - accuracy: 0.3339 - loss: 1.4988 - val_accuracy: 0.5299 - val_loss: 1.1150\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.5868 - loss: 1.0266\n",
            "Epoch 2: val_loss improved from 1.11499 to 0.87212, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 357ms/step - accuracy: 0.5871 - loss: 1.0262 - val_accuracy: 0.6575 - val_loss: 0.8721\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - accuracy: 0.6991 - loss: 0.7851\n",
            "Epoch 3: val_loss improved from 0.87212 to 0.76084, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 356ms/step - accuracy: 0.6992 - loss: 0.7849 - val_accuracy: 0.7121 - val_loss: 0.7608\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.7671 - loss: 0.6262\n",
            "Epoch 4: val_loss improved from 0.76084 to 0.71178, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 369ms/step - accuracy: 0.7672 - loss: 0.6260 - val_accuracy: 0.7381 - val_loss: 0.7118\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.8103 - loss: 0.5275\n",
            "Epoch 5: val_loss did not improve from 0.71178\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 355ms/step - accuracy: 0.8103 - loss: 0.5274 - val_accuracy: 0.7335 - val_loss: 0.7220\n",
            "Epoch 6/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 0.8361 - loss: 0.4600\n",
            "Epoch 6: val_loss improved from 0.71178 to 0.70776, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 364ms/step - accuracy: 0.8361 - loss: 0.4599 - val_accuracy: 0.7454 - val_loss: 0.7078\n",
            "Epoch 7/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - accuracy: 0.8545 - loss: 0.4095\n",
            "Epoch 7: val_loss did not improve from 0.70776\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 374ms/step - accuracy: 0.8545 - loss: 0.4094 - val_accuracy: 0.7481 - val_loss: 0.7461\n",
            "Epoch 8/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.8662 - loss: 0.3735\n",
            "Epoch 8: val_loss did not improve from 0.70776\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 346ms/step - accuracy: 0.8662 - loss: 0.3734 - val_accuracy: 0.7524 - val_loss: 0.7482\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 40ms/step\n",
            "------------------\n",
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - accuracy: 0.3325 - loss: 1.4868\n",
            "Epoch 1: val_loss improved from inf to 1.06543, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 380ms/step - accuracy: 0.3330 - loss: 1.4858 - val_accuracy: 0.5550 - val_loss: 1.0654\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.5892 - loss: 1.0092\n",
            "Epoch 2: val_loss improved from 1.06543 to 0.88230, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 355ms/step - accuracy: 0.5894 - loss: 1.0088 - val_accuracy: 0.6488 - val_loss: 0.8823\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - accuracy: 0.6965 - loss: 0.7836\n",
            "Epoch 3: val_loss improved from 0.88230 to 0.77179, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 357ms/step - accuracy: 0.6966 - loss: 0.7833 - val_accuracy: 0.7046 - val_loss: 0.7718\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.7631 - loss: 0.6345\n",
            "Epoch 4: val_loss improved from 0.77179 to 0.74534, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 369ms/step - accuracy: 0.7631 - loss: 0.6344 - val_accuracy: 0.7235 - val_loss: 0.7453\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.7989 - loss: 0.5467\n",
            "Epoch 5: val_loss did not improve from 0.74534\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 362ms/step - accuracy: 0.7989 - loss: 0.5466 - val_accuracy: 0.7304 - val_loss: 0.7536\n",
            "Epoch 6/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.8262 - loss: 0.4811\n",
            "Epoch 6: val_loss did not improve from 0.74534\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 359ms/step - accuracy: 0.8262 - loss: 0.4810 - val_accuracy: 0.7256 - val_loss: 0.7891\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step\n",
            "------------------\n",
            "Epoch 1/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.3307 - loss: 1.4933\n",
            "Epoch 1: val_loss improved from inf to 1.04392, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.3313 - loss: 1.4923 - val_accuracy: 0.5723 - val_loss: 1.0439\n",
            "Epoch 2/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.6291 - loss: 0.9516\n",
            "Epoch 2: val_loss improved from 1.04392 to 0.82492, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 371ms/step - accuracy: 0.6294 - loss: 0.9511 - val_accuracy: 0.6727 - val_loss: 0.8249\n",
            "Epoch 3/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.7273 - loss: 0.7266\n",
            "Epoch 3: val_loss improved from 0.82492 to 0.71815, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 362ms/step - accuracy: 0.7275 - loss: 0.7263 - val_accuracy: 0.7267 - val_loss: 0.7182\n",
            "Epoch 4/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.7884 - loss: 0.5800\n",
            "Epoch 4: val_loss improved from 0.71815 to 0.69820, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 361ms/step - accuracy: 0.7885 - loss: 0.5798 - val_accuracy: 0.7404 - val_loss: 0.6982\n",
            "Epoch 5/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.8267 - loss: 0.4860\n",
            "Epoch 5: val_loss improved from 0.69820 to 0.69454, saving model to nn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 361ms/step - accuracy: 0.8268 - loss: 0.4858 - val_accuracy: 0.7495 - val_loss: 0.6945\n",
            "Epoch 6/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.8515 - loss: 0.4143\n",
            "Epoch 6: val_loss did not improve from 0.69454\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 372ms/step - accuracy: 0.8516 - loss: 0.4142 - val_accuracy: 0.7490 - val_loss: 0.7269\n",
            "Epoch 7/10\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.8703 - loss: 0.3653\n",
            "Epoch 7: val_loss did not improve from 0.69454\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 364ms/step - accuracy: 0.8703 - loss: 0.3652 - val_accuracy: 0.7513 - val_loss: 0.7851\n",
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step\n",
            "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step\n",
            "------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def save_lstm_feats_to_csv(lstm_train1, lstm_test1, lstm_train2, lstm_test2, base_filename=\"lstm_features\"):\n",
        "\n",
        "    df_train1 = pd.DataFrame(lstm_train1)\n",
        "    train1_filename = f\"{base_filename}_train1.csv\"\n",
        "    df_train1.to_csv(train1_filename, index=False)\n",
        "    print(f\"'{train1_filename}' 파일로 저장 완료.\")\n",
        "\n",
        "    df_test1 = pd.DataFrame(lstm_test1)\n",
        "    test1_filename = f\"{base_filename}_test1.csv\"\n",
        "    df_test1.to_csv(test1_filename, index=False)\n",
        "    print(f\"'{test1_filename}' 파일로 저장 완료.\")\n",
        "\n",
        "    df_train2 = pd.DataFrame(lstm_train2)\n",
        "    train2_filename = f\"{base_filename}_train2.csv\"\n",
        "    df_train2.to_csv(train2_filename, index=False)\n",
        "    print(f\"'{train2_filename}' 파일로 저장 완료.\")\n",
        "\n",
        "    df_test2 = pd.DataFrame(lstm_test2)\n",
        "    test2_filename = f\"{base_filename}_test2.csv\"\n",
        "    df_test2.to_csv(test2_filename, index=False)\n",
        "    print(f\"'{test2_filename}' 파일로 저장 완료.\")\n",
        "\n",
        "# CSV 파일로 저장하는 함수를 호출합니다.\n",
        "save_lstm_feats_to_csv(lstm_train1, lstm_test1, lstm_train2, lstm_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dd16dd6-e47c-4b2c-a53d-d2fc30b71b08",
        "id": "dkR0UWR2ybII"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'lstm_features_train1.csv' 파일로 저장 완료.\n",
            "'lstm_features_test1.csv' 파일로 저장 완료.\n",
            "'lstm_features_train2.csv' 파일로 저장 완료.\n",
            "'lstm_features_test2.csv' 파일로 저장 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **앙상블 학습**"
      ],
      "metadata": {
        "id": "5cOk64bNuhLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic, CNN, GRU, LSTM 피처 불러오기\n",
        "import os\n",
        "\n",
        "# features 폴더 경로 지정\n",
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/ESAA/25-1 OB/mini project 2/features'\n",
        "\n",
        "# 폴더 내 csv 파일 불러오기 (train, test 따로)\n",
        "train_csv = [f for f in os.listdir(folder_path) if f.endswith('.csv') and 'train' in f.lower()]\n",
        "test_csv = [f for f in os.listdir(folder_path) if f.endswith('.csv') and 'test' in f.lower()]\n",
        "\n",
        "# 4. 각 파일을 DataFrame으로 읽어서 리스트에 저장\n",
        "train_features = [pd.read_csv(os.path.join(folder_path, file)) for file in train_csv]\n",
        "test_features = [pd.read_csv(os.path.join(folder_path, file)) for file in test_csv]"
      ],
      "metadata": {
        "id": "tzgrftAIfshB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 데이터프레임으로 합치기\n",
        "train_features_df = pd.concat(train_features, axis=1, ignore_index=True)\n",
        "test_features_df = pd.concat(test_features, axis=1, ignore_index=True)"
      ],
      "metadata": {
        "id": "KYIWdXKkvQl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잘 합쳐졌는지 확인 (column이 45개여야 함)\n",
        "print(train_features_df.shape)\n",
        "train_features_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "90045643-8cbf-4727-c410-a512d4d47c67",
        "id": "yu31HmK2vQl5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54879, 45)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1             2             3             4         5   \\\n",
              "0      0.000210  0.000020  2.864701e-04  9.994677e-01  1.615322e-05  0.000648   \n",
              "1      0.451201  0.091890  1.271218e-01  1.295207e-01  2.002665e-01  0.334110   \n",
              "2      0.000011  0.999989  6.469904e-08  8.570756e-08  1.150365e-10  0.000044   \n",
              "3      0.000214  0.000006  2.037654e-03  2.363783e-06  9.977409e-01  0.000489   \n",
              "4      0.000273  0.000104  8.549729e-04  9.987586e-01  9.355747e-06  0.000514   \n",
              "...         ...       ...           ...           ...           ...       ...   \n",
              "54874  0.437367  0.402492  8.113391e-02  5.575850e-02  2.324907e-02  0.287389   \n",
              "54875  0.080707  0.197824  5.063964e-01  3.188758e-02  1.831856e-01  0.077907   \n",
              "54876  0.015265  0.796027  1.289320e-02  1.754256e-01  3.890761e-04  0.021388   \n",
              "54877  0.010402  0.005244  4.179246e-02  9.366803e-01  5.881325e-03  0.033132   \n",
              "54878  0.040459  0.252173  5.965378e-01  7.767102e-02  3.315946e-02  0.179151   \n",
              "\n",
              "             6             7             8             9   ...            35  \\\n",
              "0      0.000148  1.133970e-03  9.979519e-01  1.175307e-04  ...  8.535597e-07   \n",
              "1      0.226153  1.921324e-01  8.953078e-02  1.580736e-01  ...  5.169988e-01   \n",
              "2      0.999955  8.213282e-07  8.945881e-07  1.068220e-09  ...  9.531045e-08   \n",
              "3      0.000015  8.124831e-03  1.245251e-05  9.913588e-01  ...  2.545457e-04   \n",
              "4      0.000191  1.234133e-03  9.980285e-01  3.225793e-05  ...  1.215439e-06   \n",
              "...         ...           ...           ...           ...  ...           ...   \n",
              "54874  0.346206  1.833528e-01  3.958485e-02  1.434680e-01  ...  2.288683e-02   \n",
              "54875  0.233811  4.856631e-01  5.396711e-02  1.486522e-01  ...  1.164779e-01   \n",
              "54876  0.799632  2.821165e-02  1.491129e-01  1.655510e-03  ...  6.541275e-04   \n",
              "54877  0.014365  1.578333e-01  7.544321e-01  4.023805e-02  ...  2.279359e-02   \n",
              "54878  0.177572  4.106482e-01  8.311363e-02  1.495151e-01  ...  3.013247e-01   \n",
              "\n",
              "                 36            37            38            39            40  \\\n",
              "0      2.546287e-07  4.260121e-06  9.999942e-01  4.076763e-07  3.674807e-05   \n",
              "1      3.564796e-01  8.244631e-02  2.229021e-02  2.178517e-02  5.287315e-01   \n",
              "2      9.999998e-01  8.174168e-11  1.341125e-10  3.036066e-12  7.465615e-07   \n",
              "3      4.342698e-07  9.573391e-03  9.239227e-08  9.901716e-01  2.138570e-03   \n",
              "4      5.598211e-06  4.018148e-04  9.995870e-01  4.393047e-06  1.438705e-05   \n",
              "...             ...           ...           ...           ...           ...   \n",
              "54874  9.002097e-01  6.451757e-02  1.040818e-02  1.977726e-03  7.099365e-02   \n",
              "54875  9.962648e-02  2.557128e-01  1.595149e-01  3.686680e-01  2.229027e-01   \n",
              "54876  9.827801e-01  6.157595e-04  1.592025e-02  2.975902e-05  1.647313e-03   \n",
              "54877  1.825370e-03  1.411782e-02  9.409635e-01  2.029973e-02  9.171255e-02   \n",
              "54878  5.752671e-02  2.623869e-01  1.816075e-01  1.971541e-01  2.448390e-01   \n",
              "\n",
              "             41            42            43            44  \n",
              "0      0.000016  1.006387e-04  9.998255e-01  2.096128e-05  \n",
              "1      0.321753  7.781456e-02  3.155240e-02  4.014891e-02  \n",
              "2      0.999999  3.755135e-09  2.336929e-08  1.410955e-10  \n",
              "3      0.000059  9.552764e-02  1.255973e-05  9.022618e-01  \n",
              "4      0.000049  1.128671e-03  9.987735e-01  3.421135e-05  \n",
              "...         ...           ...           ...           ...  \n",
              "54874  0.838530  6.947847e-02  1.397646e-02  7.021556e-03  \n",
              "54875  0.142703  2.398252e-01  1.589911e-01  2.355776e-01  \n",
              "54876  0.969716  1.402360e-03  2.703138e-02  2.027040e-04  \n",
              "54877  0.005213  3.389686e-02  7.882127e-01  8.096502e-02  \n",
              "54878  0.031671  2.632549e-01  2.002814e-01  2.599537e-01  \n",
              "\n",
              "[54879 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe394bbf-56ba-41e1-84a5-58e68f9ae138\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000210</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>2.864701e-04</td>\n",
              "      <td>9.994677e-01</td>\n",
              "      <td>1.615322e-05</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>1.133970e-03</td>\n",
              "      <td>9.979519e-01</td>\n",
              "      <td>1.175307e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>8.535597e-07</td>\n",
              "      <td>2.546287e-07</td>\n",
              "      <td>4.260121e-06</td>\n",
              "      <td>9.999942e-01</td>\n",
              "      <td>4.076763e-07</td>\n",
              "      <td>3.674807e-05</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>1.006387e-04</td>\n",
              "      <td>9.998255e-01</td>\n",
              "      <td>2.096128e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.451201</td>\n",
              "      <td>0.091890</td>\n",
              "      <td>1.271218e-01</td>\n",
              "      <td>1.295207e-01</td>\n",
              "      <td>2.002665e-01</td>\n",
              "      <td>0.334110</td>\n",
              "      <td>0.226153</td>\n",
              "      <td>1.921324e-01</td>\n",
              "      <td>8.953078e-02</td>\n",
              "      <td>1.580736e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>5.169988e-01</td>\n",
              "      <td>3.564796e-01</td>\n",
              "      <td>8.244631e-02</td>\n",
              "      <td>2.229021e-02</td>\n",
              "      <td>2.178517e-02</td>\n",
              "      <td>5.287315e-01</td>\n",
              "      <td>0.321753</td>\n",
              "      <td>7.781456e-02</td>\n",
              "      <td>3.155240e-02</td>\n",
              "      <td>4.014891e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.999989</td>\n",
              "      <td>6.469904e-08</td>\n",
              "      <td>8.570756e-08</td>\n",
              "      <td>1.150365e-10</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.999955</td>\n",
              "      <td>8.213282e-07</td>\n",
              "      <td>8.945881e-07</td>\n",
              "      <td>1.068220e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>9.531045e-08</td>\n",
              "      <td>9.999998e-01</td>\n",
              "      <td>8.174168e-11</td>\n",
              "      <td>1.341125e-10</td>\n",
              "      <td>3.036066e-12</td>\n",
              "      <td>7.465615e-07</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>3.755135e-09</td>\n",
              "      <td>2.336929e-08</td>\n",
              "      <td>1.410955e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>2.037654e-03</td>\n",
              "      <td>2.363783e-06</td>\n",
              "      <td>9.977409e-01</td>\n",
              "      <td>0.000489</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>8.124831e-03</td>\n",
              "      <td>1.245251e-05</td>\n",
              "      <td>9.913588e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.545457e-04</td>\n",
              "      <td>4.342698e-07</td>\n",
              "      <td>9.573391e-03</td>\n",
              "      <td>9.239227e-08</td>\n",
              "      <td>9.901716e-01</td>\n",
              "      <td>2.138570e-03</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>9.552764e-02</td>\n",
              "      <td>1.255973e-05</td>\n",
              "      <td>9.022618e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>8.549729e-04</td>\n",
              "      <td>9.987586e-01</td>\n",
              "      <td>9.355747e-06</td>\n",
              "      <td>0.000514</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>1.234133e-03</td>\n",
              "      <td>9.980285e-01</td>\n",
              "      <td>3.225793e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>1.215439e-06</td>\n",
              "      <td>5.598211e-06</td>\n",
              "      <td>4.018148e-04</td>\n",
              "      <td>9.995870e-01</td>\n",
              "      <td>4.393047e-06</td>\n",
              "      <td>1.438705e-05</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>1.128671e-03</td>\n",
              "      <td>9.987735e-01</td>\n",
              "      <td>3.421135e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54874</th>\n",
              "      <td>0.437367</td>\n",
              "      <td>0.402492</td>\n",
              "      <td>8.113391e-02</td>\n",
              "      <td>5.575850e-02</td>\n",
              "      <td>2.324907e-02</td>\n",
              "      <td>0.287389</td>\n",
              "      <td>0.346206</td>\n",
              "      <td>1.833528e-01</td>\n",
              "      <td>3.958485e-02</td>\n",
              "      <td>1.434680e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.288683e-02</td>\n",
              "      <td>9.002097e-01</td>\n",
              "      <td>6.451757e-02</td>\n",
              "      <td>1.040818e-02</td>\n",
              "      <td>1.977726e-03</td>\n",
              "      <td>7.099365e-02</td>\n",
              "      <td>0.838530</td>\n",
              "      <td>6.947847e-02</td>\n",
              "      <td>1.397646e-02</td>\n",
              "      <td>7.021556e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54875</th>\n",
              "      <td>0.080707</td>\n",
              "      <td>0.197824</td>\n",
              "      <td>5.063964e-01</td>\n",
              "      <td>3.188758e-02</td>\n",
              "      <td>1.831856e-01</td>\n",
              "      <td>0.077907</td>\n",
              "      <td>0.233811</td>\n",
              "      <td>4.856631e-01</td>\n",
              "      <td>5.396711e-02</td>\n",
              "      <td>1.486522e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.164779e-01</td>\n",
              "      <td>9.962648e-02</td>\n",
              "      <td>2.557128e-01</td>\n",
              "      <td>1.595149e-01</td>\n",
              "      <td>3.686680e-01</td>\n",
              "      <td>2.229027e-01</td>\n",
              "      <td>0.142703</td>\n",
              "      <td>2.398252e-01</td>\n",
              "      <td>1.589911e-01</td>\n",
              "      <td>2.355776e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54876</th>\n",
              "      <td>0.015265</td>\n",
              "      <td>0.796027</td>\n",
              "      <td>1.289320e-02</td>\n",
              "      <td>1.754256e-01</td>\n",
              "      <td>3.890761e-04</td>\n",
              "      <td>0.021388</td>\n",
              "      <td>0.799632</td>\n",
              "      <td>2.821165e-02</td>\n",
              "      <td>1.491129e-01</td>\n",
              "      <td>1.655510e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>6.541275e-04</td>\n",
              "      <td>9.827801e-01</td>\n",
              "      <td>6.157595e-04</td>\n",
              "      <td>1.592025e-02</td>\n",
              "      <td>2.975902e-05</td>\n",
              "      <td>1.647313e-03</td>\n",
              "      <td>0.969716</td>\n",
              "      <td>1.402360e-03</td>\n",
              "      <td>2.703138e-02</td>\n",
              "      <td>2.027040e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54877</th>\n",
              "      <td>0.010402</td>\n",
              "      <td>0.005244</td>\n",
              "      <td>4.179246e-02</td>\n",
              "      <td>9.366803e-01</td>\n",
              "      <td>5.881325e-03</td>\n",
              "      <td>0.033132</td>\n",
              "      <td>0.014365</td>\n",
              "      <td>1.578333e-01</td>\n",
              "      <td>7.544321e-01</td>\n",
              "      <td>4.023805e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>2.279359e-02</td>\n",
              "      <td>1.825370e-03</td>\n",
              "      <td>1.411782e-02</td>\n",
              "      <td>9.409635e-01</td>\n",
              "      <td>2.029973e-02</td>\n",
              "      <td>9.171255e-02</td>\n",
              "      <td>0.005213</td>\n",
              "      <td>3.389686e-02</td>\n",
              "      <td>7.882127e-01</td>\n",
              "      <td>8.096502e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54878</th>\n",
              "      <td>0.040459</td>\n",
              "      <td>0.252173</td>\n",
              "      <td>5.965378e-01</td>\n",
              "      <td>7.767102e-02</td>\n",
              "      <td>3.315946e-02</td>\n",
              "      <td>0.179151</td>\n",
              "      <td>0.177572</td>\n",
              "      <td>4.106482e-01</td>\n",
              "      <td>8.311363e-02</td>\n",
              "      <td>1.495151e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>3.013247e-01</td>\n",
              "      <td>5.752671e-02</td>\n",
              "      <td>2.623869e-01</td>\n",
              "      <td>1.816075e-01</td>\n",
              "      <td>1.971541e-01</td>\n",
              "      <td>2.448390e-01</td>\n",
              "      <td>0.031671</td>\n",
              "      <td>2.632549e-01</td>\n",
              "      <td>2.002814e-01</td>\n",
              "      <td>2.599537e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54879 rows × 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe394bbf-56ba-41e1-84a5-58e68f9ae138')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe394bbf-56ba-41e1-84a5-58e68f9ae138 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe394bbf-56ba-41e1-84a5-58e68f9ae138');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c56ab902-c494-433a-a4f2-425a4232fabf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c56ab902-c494-433a-a4f2-425a4232fabf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c56ab902-c494-433a-a4f2-425a4232fabf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7c0cb425-d6f1-4776-8578-7c0a0426cc29\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_features_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7c0cb425-d6f1-4776-8578-7c0a0426cc29 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_features_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_features_df"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_nn_train = train_features_df.copy()\n",
        "all_nn_test = test_features_df.copy()\n",
        "\n",
        "# 최종 앙상블 데이터\n",
        "cols_to_drop = ['index', 'text']\n",
        "train_X = train.drop(cols_to_drop+['author'], axis=1).values\n",
        "test_X = test.drop(cols_to_drop, axis=1).values\n",
        "train_X = np.hstack([train_X,train_svd,train_svd2])\n",
        "test_X = np.hstack([test_X,test_svd,test_svd2])\n",
        "\n",
        "f_train_X = np.hstack([train_X, all_nn_train])\n",
        "f_train_X = np.round(f_train_X,4)\n",
        "f_test_X = np.hstack([test_X, all_nn_test])\n",
        "f_test_X = np.round(f_test_X,4)\n",
        "print(f_train_X.shape, f_test_X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c7a6dc0-8310-4c4a-c1b5-bc80081a72ee",
        "id": "clDAQFyqvQl5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54879, 168) (19617, 168)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Logistic Regression을 최종 모델로 스태킹 학습 진행**\n",
        "\n",
        "- StandardScaler로 정규화\n",
        "- f_train_X, f_test_x를 Logistic Regression으로 학습\n"
      ],
      "metadata": {
        "id": "DP8_8snNvAp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import log_loss, accuracy_score"
      ],
      "metadata": {
        "id": "l7TErZjqvAp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StandardScaler로 정규화\n",
        "scaler = StandardScaler()\n",
        "f_train_X_scaled = scaler.fit_transform(f_train_X)\n",
        "f_test_X_scaled = scaler.transform(f_test_X)\n",
        "train_Y = train['author']"
      ],
      "metadata": {
        "id": "t4q5Lvx3vAqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 Logistic Regression 모델 학습 및 예측\n",
        "clf = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='lbfgs',\n",
        "    penalty='l2',\n",
        "    C=1.0,\n",
        "    max_iter=1000\n",
        ")\n",
        "clf.fit(f_train_X_scaled, train_Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "f1b7fa4b-1625-4b60-bae6-2589982007ba",
        "id": "qvdn6CZevAqA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000, multi_class='multinomial')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cv_logreg_submit(k_cnt=3, s_flag=False):\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(f_train_X)\n",
        "    X_test_scaled = scaler.transform(f_test_X)\n",
        "    y = train['author'].values\n",
        "\n",
        "    if s_flag:\n",
        "        kf = StratifiedKFold(n_splits=k_cnt, shuffle=True, random_state=42)\n",
        "    else:\n",
        "        kf = KFold(n_splits=k_cnt, shuffle=True, random_state=42)\n",
        "\n",
        "    preds_per_fold = []\n",
        "    weights = []\n",
        "    org_train_pred = np.zeros((X_scaled.shape[0], 5))\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled, y)):\n",
        "        X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        model = LogisticRegression(\n",
        "            multi_class='multinomial',\n",
        "            solver='lbfgs',\n",
        "            penalty='l2',\n",
        "            C=1.0,\n",
        "            max_iter=1000\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        val_pred = model.predict_proba(X_val)\n",
        "        full_train_pred = model.predict_proba(X_scaled)\n",
        "        test_fold_pred = model.predict_proba(X_test_scaled)\n",
        "\n",
        "        val_loss = log_loss(y_val, val_pred)\n",
        "        print(f\"[Fold {fold}] Log loss: {val_loss:.5f}\")\n",
        "        preds_per_fold.append((test_fold_pred, val_loss))\n",
        "        weights.append(1.0 / val_loss)\n",
        "        org_train_pred += full_train_pred\n",
        "\n",
        "    org_train_pred /= k_cnt\n",
        "    avg_k_score = np.mean([v for _, v in preds_per_fold])\n",
        "\n",
        "    # 평균 앙상블\n",
        "    test_pred_avg = np.mean([p for p, _ in preds_per_fold], axis=0)\n",
        "\n",
        "    # 가중 앙상블 (loss의 역수 가중치)\n",
        "    weight_sum = sum(weights)\n",
        "    test_pred_weighted = sum(p * w for (p, _), w in zip(preds_per_fold, weights)) / weight_sum\n",
        "\n",
        "    # 최고 fold 예측\n",
        "    best_fold_pred = min(preds_per_fold, key=lambda x: x[1])[0]\n",
        "\n",
        "    # 저장 함수\n",
        "    def save_pred(pred, filename):\n",
        "        submiss = pd.read_csv(\"/content/drive/MyDrive/ESAA_OB/Dataset/novel_sample_submission.csv\")\n",
        "        pred = np.round(pred, 4)\n",
        "        for i in range(5):\n",
        "            submiss[str(i)] = pred[:, i]\n",
        "        submiss.to_csv(filename, index=False)\n",
        "\n",
        "    # 파일 각각 저장\n",
        "    save_pred(test_pred_avg, f\"logreg_avg_{k_cnt}.csv\")\n",
        "\n",
        "    # 성능 출력\n",
        "    print(\"✅ Local average valid log loss:\", avg_k_score)\n",
        "    print(\"✅ Full train OOF log loss:\", log_loss(y, org_train_pred))"
      ],
      "metadata": {
        "id": "kN9LjH9rvAqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_logreg_submit(k_cnt=5, s_flag=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92faf105-28bb-406c-9ab1-8740209377b4",
        "id": "dnyfX5VsvAqB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0] Log loss: 0.48223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Log loss: 0.47525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Log loss: 0.47266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 3] Log loss: 0.47424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 4] Log loss: 0.46914\n",
            "✅ Local average valid log loss: 0.4747055800557282\n",
            "✅ Full train OOF log loss: 0.46091900674167563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 하이퍼 파라미터 튜닝\n",
        "# param_grid = {\n",
        "#     'C': [0.01, 0.1, 1, 10],\n",
        "#     'solver': ['lbfgs', 'newton-cg'],\n",
        "#     'max_iter': [500, 1000]\n",
        "# }\n",
        "\n",
        "# grid_clf = GridSearchCV(\n",
        "#     LogisticRegression(multi_class='multinomial', penalty='l2'),\n",
        "#     param_grid,\n",
        "#     cv=5,\n",
        "#     scoring='neg_log_loss',\n",
        "#     verbose=1,\n",
        "#     n_jobs=-1\n",
        "# )\n",
        "\n",
        "# grid_clf.fit(f_train_X_scaled, train_Y)\n",
        "\n",
        "# print(\"Best parameters:\", grid_clf.best_params_)\n",
        "# print(\"Best log loss:\", -grid_clf.best_score_)\n",
        "\n",
        "# # 최적 모델로 예측\n",
        "# best_clf = grid_clf.best_estimator_\n",
        "# test_pred_best = best_clf.predict_proba(f_test_X_scaled)"
      ],
      "metadata": {
        "id": "FTp6ixlEvAqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "k_cnt = 5\n",
        "# 다운로드할 파일 리스트\n",
        "files.download(f'logreg_avg_{k_cnt}.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b3656731-cd3b-4336-d442-4bf55fef9b45",
        "id": "FEkVbnxgvAqC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3f232c64-ef1a-41b9-a555-70aab4d93917\", \"logreg_avg_5.csv\", 777687)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_199ae1c7-c03f-4486-8743-c5e4a65dd433\", \"logreg_weighted_5.csv\", 777727)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a054c825-7b6d-4f9c-bc15-24a1ed22871b\", \"logreg_single_5.csv\", 777379)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **XGB를 최종 모델로 스태킹 학습 진행**"
      ],
      "metadata": {
        "id": "1HwlHrM4_WqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 데이터프레임으로 합치기\n",
        "train_features_df = pd.concat(train_features, axis=1, ignore_index=True)\n",
        "test_features_df = pd.concat(test_features, axis=1, ignore_index=True)"
      ],
      "metadata": {
        "id": "z6Va7p9GhFh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잘 합쳐졌는지 확인 (column이 45개여야 함)\n",
        "print(train_features_df.shape)\n",
        "train_features_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "ci8sn_OjiEFj",
        "outputId": "90045643-8cbf-4727-c410-a512d4d47c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54879, 45)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1             2             3             4         5   \\\n",
              "0      0.000210  0.000020  2.864701e-04  9.994677e-01  1.615322e-05  0.000648   \n",
              "1      0.451201  0.091890  1.271218e-01  1.295207e-01  2.002665e-01  0.334110   \n",
              "2      0.000011  0.999989  6.469904e-08  8.570756e-08  1.150365e-10  0.000044   \n",
              "3      0.000214  0.000006  2.037654e-03  2.363783e-06  9.977409e-01  0.000489   \n",
              "4      0.000273  0.000104  8.549729e-04  9.987586e-01  9.355747e-06  0.000514   \n",
              "...         ...       ...           ...           ...           ...       ...   \n",
              "54874  0.437367  0.402492  8.113391e-02  5.575850e-02  2.324907e-02  0.287389   \n",
              "54875  0.080707  0.197824  5.063964e-01  3.188758e-02  1.831856e-01  0.077907   \n",
              "54876  0.015265  0.796027  1.289320e-02  1.754256e-01  3.890761e-04  0.021388   \n",
              "54877  0.010402  0.005244  4.179246e-02  9.366803e-01  5.881325e-03  0.033132   \n",
              "54878  0.040459  0.252173  5.965378e-01  7.767102e-02  3.315946e-02  0.179151   \n",
              "\n",
              "             6             7             8             9   ...            35  \\\n",
              "0      0.000148  1.133970e-03  9.979519e-01  1.175307e-04  ...  8.535597e-07   \n",
              "1      0.226153  1.921324e-01  8.953078e-02  1.580736e-01  ...  5.169988e-01   \n",
              "2      0.999955  8.213282e-07  8.945881e-07  1.068220e-09  ...  9.531045e-08   \n",
              "3      0.000015  8.124831e-03  1.245251e-05  9.913588e-01  ...  2.545457e-04   \n",
              "4      0.000191  1.234133e-03  9.980285e-01  3.225793e-05  ...  1.215439e-06   \n",
              "...         ...           ...           ...           ...  ...           ...   \n",
              "54874  0.346206  1.833528e-01  3.958485e-02  1.434680e-01  ...  2.288683e-02   \n",
              "54875  0.233811  4.856631e-01  5.396711e-02  1.486522e-01  ...  1.164779e-01   \n",
              "54876  0.799632  2.821165e-02  1.491129e-01  1.655510e-03  ...  6.541275e-04   \n",
              "54877  0.014365  1.578333e-01  7.544321e-01  4.023805e-02  ...  2.279359e-02   \n",
              "54878  0.177572  4.106482e-01  8.311363e-02  1.495151e-01  ...  3.013247e-01   \n",
              "\n",
              "                 36            37            38            39            40  \\\n",
              "0      2.546287e-07  4.260121e-06  9.999942e-01  4.076763e-07  3.674807e-05   \n",
              "1      3.564796e-01  8.244631e-02  2.229021e-02  2.178517e-02  5.287315e-01   \n",
              "2      9.999998e-01  8.174168e-11  1.341125e-10  3.036066e-12  7.465615e-07   \n",
              "3      4.342698e-07  9.573391e-03  9.239227e-08  9.901716e-01  2.138570e-03   \n",
              "4      5.598211e-06  4.018148e-04  9.995870e-01  4.393047e-06  1.438705e-05   \n",
              "...             ...           ...           ...           ...           ...   \n",
              "54874  9.002097e-01  6.451757e-02  1.040818e-02  1.977726e-03  7.099365e-02   \n",
              "54875  9.962648e-02  2.557128e-01  1.595149e-01  3.686680e-01  2.229027e-01   \n",
              "54876  9.827801e-01  6.157595e-04  1.592025e-02  2.975902e-05  1.647313e-03   \n",
              "54877  1.825370e-03  1.411782e-02  9.409635e-01  2.029973e-02  9.171255e-02   \n",
              "54878  5.752671e-02  2.623869e-01  1.816075e-01  1.971541e-01  2.448390e-01   \n",
              "\n",
              "             41            42            43            44  \n",
              "0      0.000016  1.006387e-04  9.998255e-01  2.096128e-05  \n",
              "1      0.321753  7.781456e-02  3.155240e-02  4.014891e-02  \n",
              "2      0.999999  3.755135e-09  2.336929e-08  1.410955e-10  \n",
              "3      0.000059  9.552764e-02  1.255973e-05  9.022618e-01  \n",
              "4      0.000049  1.128671e-03  9.987735e-01  3.421135e-05  \n",
              "...         ...           ...           ...           ...  \n",
              "54874  0.838530  6.947847e-02  1.397646e-02  7.021556e-03  \n",
              "54875  0.142703  2.398252e-01  1.589911e-01  2.355776e-01  \n",
              "54876  0.969716  1.402360e-03  2.703138e-02  2.027040e-04  \n",
              "54877  0.005213  3.389686e-02  7.882127e-01  8.096502e-02  \n",
              "54878  0.031671  2.632549e-01  2.002814e-01  2.599537e-01  \n",
              "\n",
              "[54879 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe394bbf-56ba-41e1-84a5-58e68f9ae138\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000210</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>2.864701e-04</td>\n",
              "      <td>9.994677e-01</td>\n",
              "      <td>1.615322e-05</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>1.133970e-03</td>\n",
              "      <td>9.979519e-01</td>\n",
              "      <td>1.175307e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>8.535597e-07</td>\n",
              "      <td>2.546287e-07</td>\n",
              "      <td>4.260121e-06</td>\n",
              "      <td>9.999942e-01</td>\n",
              "      <td>4.076763e-07</td>\n",
              "      <td>3.674807e-05</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>1.006387e-04</td>\n",
              "      <td>9.998255e-01</td>\n",
              "      <td>2.096128e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.451201</td>\n",
              "      <td>0.091890</td>\n",
              "      <td>1.271218e-01</td>\n",
              "      <td>1.295207e-01</td>\n",
              "      <td>2.002665e-01</td>\n",
              "      <td>0.334110</td>\n",
              "      <td>0.226153</td>\n",
              "      <td>1.921324e-01</td>\n",
              "      <td>8.953078e-02</td>\n",
              "      <td>1.580736e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>5.169988e-01</td>\n",
              "      <td>3.564796e-01</td>\n",
              "      <td>8.244631e-02</td>\n",
              "      <td>2.229021e-02</td>\n",
              "      <td>2.178517e-02</td>\n",
              "      <td>5.287315e-01</td>\n",
              "      <td>0.321753</td>\n",
              "      <td>7.781456e-02</td>\n",
              "      <td>3.155240e-02</td>\n",
              "      <td>4.014891e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.999989</td>\n",
              "      <td>6.469904e-08</td>\n",
              "      <td>8.570756e-08</td>\n",
              "      <td>1.150365e-10</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.999955</td>\n",
              "      <td>8.213282e-07</td>\n",
              "      <td>8.945881e-07</td>\n",
              "      <td>1.068220e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>9.531045e-08</td>\n",
              "      <td>9.999998e-01</td>\n",
              "      <td>8.174168e-11</td>\n",
              "      <td>1.341125e-10</td>\n",
              "      <td>3.036066e-12</td>\n",
              "      <td>7.465615e-07</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>3.755135e-09</td>\n",
              "      <td>2.336929e-08</td>\n",
              "      <td>1.410955e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>2.037654e-03</td>\n",
              "      <td>2.363783e-06</td>\n",
              "      <td>9.977409e-01</td>\n",
              "      <td>0.000489</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>8.124831e-03</td>\n",
              "      <td>1.245251e-05</td>\n",
              "      <td>9.913588e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.545457e-04</td>\n",
              "      <td>4.342698e-07</td>\n",
              "      <td>9.573391e-03</td>\n",
              "      <td>9.239227e-08</td>\n",
              "      <td>9.901716e-01</td>\n",
              "      <td>2.138570e-03</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>9.552764e-02</td>\n",
              "      <td>1.255973e-05</td>\n",
              "      <td>9.022618e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>8.549729e-04</td>\n",
              "      <td>9.987586e-01</td>\n",
              "      <td>9.355747e-06</td>\n",
              "      <td>0.000514</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>1.234133e-03</td>\n",
              "      <td>9.980285e-01</td>\n",
              "      <td>3.225793e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>1.215439e-06</td>\n",
              "      <td>5.598211e-06</td>\n",
              "      <td>4.018148e-04</td>\n",
              "      <td>9.995870e-01</td>\n",
              "      <td>4.393047e-06</td>\n",
              "      <td>1.438705e-05</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>1.128671e-03</td>\n",
              "      <td>9.987735e-01</td>\n",
              "      <td>3.421135e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54874</th>\n",
              "      <td>0.437367</td>\n",
              "      <td>0.402492</td>\n",
              "      <td>8.113391e-02</td>\n",
              "      <td>5.575850e-02</td>\n",
              "      <td>2.324907e-02</td>\n",
              "      <td>0.287389</td>\n",
              "      <td>0.346206</td>\n",
              "      <td>1.833528e-01</td>\n",
              "      <td>3.958485e-02</td>\n",
              "      <td>1.434680e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.288683e-02</td>\n",
              "      <td>9.002097e-01</td>\n",
              "      <td>6.451757e-02</td>\n",
              "      <td>1.040818e-02</td>\n",
              "      <td>1.977726e-03</td>\n",
              "      <td>7.099365e-02</td>\n",
              "      <td>0.838530</td>\n",
              "      <td>6.947847e-02</td>\n",
              "      <td>1.397646e-02</td>\n",
              "      <td>7.021556e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54875</th>\n",
              "      <td>0.080707</td>\n",
              "      <td>0.197824</td>\n",
              "      <td>5.063964e-01</td>\n",
              "      <td>3.188758e-02</td>\n",
              "      <td>1.831856e-01</td>\n",
              "      <td>0.077907</td>\n",
              "      <td>0.233811</td>\n",
              "      <td>4.856631e-01</td>\n",
              "      <td>5.396711e-02</td>\n",
              "      <td>1.486522e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.164779e-01</td>\n",
              "      <td>9.962648e-02</td>\n",
              "      <td>2.557128e-01</td>\n",
              "      <td>1.595149e-01</td>\n",
              "      <td>3.686680e-01</td>\n",
              "      <td>2.229027e-01</td>\n",
              "      <td>0.142703</td>\n",
              "      <td>2.398252e-01</td>\n",
              "      <td>1.589911e-01</td>\n",
              "      <td>2.355776e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54876</th>\n",
              "      <td>0.015265</td>\n",
              "      <td>0.796027</td>\n",
              "      <td>1.289320e-02</td>\n",
              "      <td>1.754256e-01</td>\n",
              "      <td>3.890761e-04</td>\n",
              "      <td>0.021388</td>\n",
              "      <td>0.799632</td>\n",
              "      <td>2.821165e-02</td>\n",
              "      <td>1.491129e-01</td>\n",
              "      <td>1.655510e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>6.541275e-04</td>\n",
              "      <td>9.827801e-01</td>\n",
              "      <td>6.157595e-04</td>\n",
              "      <td>1.592025e-02</td>\n",
              "      <td>2.975902e-05</td>\n",
              "      <td>1.647313e-03</td>\n",
              "      <td>0.969716</td>\n",
              "      <td>1.402360e-03</td>\n",
              "      <td>2.703138e-02</td>\n",
              "      <td>2.027040e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54877</th>\n",
              "      <td>0.010402</td>\n",
              "      <td>0.005244</td>\n",
              "      <td>4.179246e-02</td>\n",
              "      <td>9.366803e-01</td>\n",
              "      <td>5.881325e-03</td>\n",
              "      <td>0.033132</td>\n",
              "      <td>0.014365</td>\n",
              "      <td>1.578333e-01</td>\n",
              "      <td>7.544321e-01</td>\n",
              "      <td>4.023805e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>2.279359e-02</td>\n",
              "      <td>1.825370e-03</td>\n",
              "      <td>1.411782e-02</td>\n",
              "      <td>9.409635e-01</td>\n",
              "      <td>2.029973e-02</td>\n",
              "      <td>9.171255e-02</td>\n",
              "      <td>0.005213</td>\n",
              "      <td>3.389686e-02</td>\n",
              "      <td>7.882127e-01</td>\n",
              "      <td>8.096502e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54878</th>\n",
              "      <td>0.040459</td>\n",
              "      <td>0.252173</td>\n",
              "      <td>5.965378e-01</td>\n",
              "      <td>7.767102e-02</td>\n",
              "      <td>3.315946e-02</td>\n",
              "      <td>0.179151</td>\n",
              "      <td>0.177572</td>\n",
              "      <td>4.106482e-01</td>\n",
              "      <td>8.311363e-02</td>\n",
              "      <td>1.495151e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>3.013247e-01</td>\n",
              "      <td>5.752671e-02</td>\n",
              "      <td>2.623869e-01</td>\n",
              "      <td>1.816075e-01</td>\n",
              "      <td>1.971541e-01</td>\n",
              "      <td>2.448390e-01</td>\n",
              "      <td>0.031671</td>\n",
              "      <td>2.632549e-01</td>\n",
              "      <td>2.002814e-01</td>\n",
              "      <td>2.599537e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54879 rows × 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe394bbf-56ba-41e1-84a5-58e68f9ae138')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe394bbf-56ba-41e1-84a5-58e68f9ae138 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe394bbf-56ba-41e1-84a5-58e68f9ae138');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c56ab902-c494-433a-a4f2-425a4232fabf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c56ab902-c494-433a-a4f2-425a4232fabf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c56ab902-c494-433a-a4f2-425a4232fabf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7c0cb425-d6f1-4776-8578-7c0a0426cc29\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_features_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7c0cb425-d6f1-4776-8578-7c0a0426cc29 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_features_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_features_df"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_nn_train = train_features_df.copy()\n",
        "all_nn_test = test_features_df.copy()\n",
        "\n",
        "# 최종 앙상블 데이터\n",
        "cols_to_drop = ['index', 'text']\n",
        "train_X = train.drop(cols_to_drop+['author'], axis=1).values\n",
        "test_X = test.drop(cols_to_drop, axis=1).values\n",
        "train_X = np.hstack([train_X,train_svd,train_svd2])\n",
        "test_X = np.hstack([test_X,test_svd,test_svd2])\n",
        "\n",
        "f_train_X = np.hstack([train_X, all_nn_train])\n",
        "f_train_X = np.round(f_train_X,4)\n",
        "f_test_X = np.hstack([test_X, all_nn_test])\n",
        "f_test_X = np.round(f_test_X,4)\n",
        "print(f_train_X.shape, f_test_X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fsh788-givNd",
        "outputId": "3c7a6dc0-8310-4c4a-c1b5-bc80081a72ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54879, 168) (19617, 168)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "train_Y = train['author']\n",
        "\n",
        "# 최종 앙상블입니다.\n",
        "def cv_test(k_cnt=3, s_flag = False):\n",
        "    rnd = 42\n",
        "    if s_flag:\n",
        "        kf = StratifiedKFold(n_splits=k_cnt, shuffle=True, random_state=rnd)\n",
        "    else:\n",
        "        kf = KFold(n_splits=k_cnt, shuffle=True, random_state=rnd)\n",
        "    test_pred = None\n",
        "    weighted_test_pred = None\n",
        "    org_train_pred = None\n",
        "    avg_k_score = 0\n",
        "    reverse_score = 0\n",
        "    best_loss = 100\n",
        "    best_single_pred = None\n",
        "    for train_index, test_index in kf.split(f_train_X,train_Y):\n",
        "        X_train, X_test = f_train_X[train_index], f_train_X[test_index]\n",
        "        y_train, y_test = train_Y[train_index], train_Y[test_index]\n",
        "        params = {\n",
        "                'colsample_bytree': 0.7,\n",
        "                'subsample': 0.8,\n",
        "                'eta': 0.04,\n",
        "                'max_depth': 3,\n",
        "                'eval_metric':'mlogloss',\n",
        "                'objective':'multi:softprob',\n",
        "                'num_class':5,\n",
        "                'tree_method':'hist'\n",
        "        }\n",
        "\n",
        "        d_train = xgb.DMatrix(X_train, y_train)\n",
        "        d_valid = xgb.DMatrix(X_test, y_test)\n",
        "        d_test = xgb.DMatrix(f_test_X)\n",
        "\n",
        "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
        "        m = xgb.train(params, d_train, 2000, watchlist,\n",
        "                        early_stopping_rounds=50,\n",
        "                        verbose_eval=200)\n",
        "\n",
        "        train_pred = m.predict(d_train)\n",
        "        valid_pred = m.predict(d_valid)\n",
        "        tmp_train_pred = m.predict(xgb.DMatrix(f_train_X))\n",
        "\n",
        "        train_score = log_loss(y_train,train_pred)\n",
        "        valid_score = log_loss(y_test,valid_pred)\n",
        "        print('train log loss',train_score,'valid log loss',valid_score)\n",
        "        avg_k_score += valid_score\n",
        "        rev_valid_score = 1.0/valid_score\n",
        "        reverse_score += rev_valid_score\n",
        "        print('rev',rev_valid_score)\n",
        "\n",
        "        if test_pred is None:\n",
        "            test_pred = m.predict(d_test)\n",
        "            weighted_test_pred = test_pred*rev_valid_score\n",
        "            org_train_pred = tmp_train_pred\n",
        "            best_loss = valid_score\n",
        "            best_single_pred = test_pred\n",
        "        else:\n",
        "            curr_pred = m.predict(d_test)\n",
        "            test_pred += curr_pred\n",
        "            weighted_test_pred += curr_pred*rev_valid_score\n",
        "            org_train_pred += tmp_train_pred\n",
        "\n",
        "            if valid_score < best_loss:\n",
        "                print('BETTER')\n",
        "                best_loss = valid_score\n",
        "                best_single_pred = curr_pred\n",
        "\n",
        "    test_pred = test_pred / k_cnt\n",
        "    test_pred = np.round(test_pred,4)\n",
        "    org_train_pred = org_train_pred / k_cnt\n",
        "    avg_k_score = avg_k_score/k_cnt\n",
        "\n",
        "    submiss=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ESAA/25-1 OB/mini project 2/sample_submission.csv\")\n",
        "    submiss['0']=test_pred[:,0]\n",
        "    submiss['1']=test_pred[:,1]\n",
        "    submiss['2']=test_pred[:,2]\n",
        "    submiss['3']=test_pred[:,3]\n",
        "    submiss['4']=test_pred[:,4]\n",
        "    submiss.to_csv(\"xgb_{}.csv\".format(k_cnt),index=False)\n",
        "    print(reverse_score)\n",
        "    # weigthed\n",
        "    submiss=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ESAA/25-1 OB/mini project 2/sample_submission.csv\")\n",
        "    weighted_test_pred = weighted_test_pred / reverse_score\n",
        "    weighted_test_pred = np.round(weighted_test_pred,4)\n",
        "    submiss['0']=weighted_test_pred[:,0]\n",
        "    submiss['1']=weighted_test_pred[:,1]\n",
        "    submiss['2']=weighted_test_pred[:,2]\n",
        "    submiss['3']=weighted_test_pred[:,3]\n",
        "    submiss['4']=weighted_test_pred[:,4]\n",
        "    submiss.to_csv(\"weighted_{}.csv\".format(k_cnt),index=False)\n",
        "    # best single\n",
        "    submiss=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ESAA/25-1 OB/mini project 2/sample_submission.csv\")\n",
        "    weighted_test_pred = np.round(best_single_pred,4)\n",
        "    submiss['0']=weighted_test_pred[:,0]\n",
        "    submiss['1']=weighted_test_pred[:,1]\n",
        "    submiss['2']=weighted_test_pred[:,2]\n",
        "    submiss['3']=weighted_test_pred[:,3]\n",
        "    submiss['4']=weighted_test_pred[:,4]\n",
        "    submiss.to_csv(\"single_{}.csv\".format(k_cnt),index=False)\n",
        "\n",
        "    # train log loss\n",
        "    print('local average valid loss',avg_k_score)\n",
        "    print('train log loss', log_loss(train_Y,org_train_pred))"
      ],
      "metadata": {
        "id": "boUshSE7C0Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_test(5, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tpCi4PxDtde",
        "outputId": "658ea741-1c20-4bbe-dcb2-860be364f4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:723: FutureWarning: Pass `evals` as keyword args.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-mlogloss:1.54568\tvalid-mlogloss:1.54587\n",
            "[200]\ttrain-mlogloss:0.43438\tvalid-mlogloss:0.45828\n",
            "[400]\ttrain-mlogloss:0.39884\tvalid-mlogloss:0.44602\n",
            "[600]\ttrain-mlogloss:0.37243\tvalid-mlogloss:0.44139\n",
            "[800]\ttrain-mlogloss:0.35013\tvalid-mlogloss:0.43885\n",
            "[1000]\ttrain-mlogloss:0.32967\tvalid-mlogloss:0.43702\n",
            "[1200]\ttrain-mlogloss:0.31151\tvalid-mlogloss:0.43610\n",
            "[1282]\ttrain-mlogloss:0.30451\tvalid-mlogloss:0.43597\n",
            "train log loss 0.3045114176673922 valid log loss 0.4359743203816037\n",
            "rev 2.293713077239757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:723: FutureWarning: Pass `evals` as keyword args.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-mlogloss:1.54562\tvalid-mlogloss:1.54595\n",
            "[200]\ttrain-mlogloss:0.43420\tvalid-mlogloss:0.45623\n",
            "[400]\ttrain-mlogloss:0.39901\tvalid-mlogloss:0.44523\n",
            "[600]\ttrain-mlogloss:0.37265\tvalid-mlogloss:0.44061\n",
            "[800]\ttrain-mlogloss:0.35005\tvalid-mlogloss:0.43839\n",
            "[1000]\ttrain-mlogloss:0.33003\tvalid-mlogloss:0.43722\n",
            "[1130]\ttrain-mlogloss:0.31789\tvalid-mlogloss:0.43692\n",
            "train log loss 0.3178864752714442 valid log loss 0.43692326301304124\n",
            "rev 2.2887314195723016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:723: FutureWarning: Pass `evals` as keyword args.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-mlogloss:1.54563\tvalid-mlogloss:1.54569\n",
            "[200]\ttrain-mlogloss:0.43519\tvalid-mlogloss:0.45203\n",
            "[400]\ttrain-mlogloss:0.40010\tvalid-mlogloss:0.44000\n",
            "[600]\ttrain-mlogloss:0.37410\tvalid-mlogloss:0.43545\n",
            "[800]\ttrain-mlogloss:0.35174\tvalid-mlogloss:0.43282\n",
            "[1000]\ttrain-mlogloss:0.33161\tvalid-mlogloss:0.43090\n",
            "[1124]\ttrain-mlogloss:0.31999\tvalid-mlogloss:0.43066\n",
            "train log loss 0.31989001674991835 valid log loss 0.4306436305102449\n",
            "rev 2.3221056324812177\n",
            "BETTER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:723: FutureWarning: Pass `evals` as keyword args.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-mlogloss:1.54557\tvalid-mlogloss:1.54614\n",
            "[200]\ttrain-mlogloss:0.43481\tvalid-mlogloss:0.45534\n",
            "[400]\ttrain-mlogloss:0.39931\tvalid-mlogloss:0.44363\n",
            "[600]\ttrain-mlogloss:0.37314\tvalid-mlogloss:0.43960\n",
            "[800]\ttrain-mlogloss:0.35024\tvalid-mlogloss:0.43709\n",
            "[1000]\ttrain-mlogloss:0.32978\tvalid-mlogloss:0.43579\n",
            "[1175]\ttrain-mlogloss:0.31350\tvalid-mlogloss:0.43514\n",
            "train log loss 0.313419920561722 valid log loss 0.43513855779399474\n",
            "rev 2.298118569564742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:723: FutureWarning: Pass `evals` as keyword args.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-mlogloss:1.54549\tvalid-mlogloss:1.54566\n",
            "[200]\ttrain-mlogloss:0.43494\tvalid-mlogloss:0.45615\n",
            "[400]\ttrain-mlogloss:0.39971\tvalid-mlogloss:0.44314\n",
            "[600]\ttrain-mlogloss:0.37310\tvalid-mlogloss:0.43774\n",
            "[800]\ttrain-mlogloss:0.35050\tvalid-mlogloss:0.43543\n",
            "[1000]\ttrain-mlogloss:0.33056\tvalid-mlogloss:0.43390\n",
            "[1200]\ttrain-mlogloss:0.31201\tvalid-mlogloss:0.43274\n",
            "[1400]\ttrain-mlogloss:0.29534\tvalid-mlogloss:0.43195\n",
            "[1545]\ttrain-mlogloss:0.28373\tvalid-mlogloss:0.43171\n",
            "train log loss 0.28373377787923365 valid log loss 0.43170858996423583\n",
            "rev 2.3163773509413916\n",
            "11.51904604979941\n",
            "local average valid loss 0.43407767233262406\n",
            "train log loss 0.3237289203387155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LGBM을 최종 모델로 스태킹 학습 진행**"
      ],
      "metadata": {
        "id": "dmd9oIe1wCVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_Y = train['author']\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 최종 앙상블입니다.\n",
        "def cv_test_lgbm(k_cnt=3, s_flag = False):\n",
        "    rnd = 42\n",
        "    if s_flag:\n",
        "        kf = StratifiedKFold(n_splits=k_cnt, shuffle=True, random_state=rnd)\n",
        "    else:\n",
        "        kf = KFold(n_splits=k_cnt, shuffle=True, random_state=rnd)\n",
        "    test_pred = None\n",
        "    weighted_test_pred = None\n",
        "    org_train_pred = None\n",
        "    avg_k_score = 0\n",
        "    reverse_score = 0\n",
        "    best_loss = 100\n",
        "    best_single_pred = None\n",
        "    for train_index, test_index in kf.split(f_train_X,train_Y):\n",
        "        X_train, X_test = f_train_X[train_index], f_train_X[test_index]\n",
        "        y_train, y_test = train_Y[train_index], train_Y[test_index]\n",
        "        params = {\n",
        "            'objective': 'multiclass',\n",
        "            'metric': 'multi_logloss',\n",
        "            'num_class': 5,\n",
        "            'boosting_type': 'gbdt',\n",
        "            'n_estimators': 2000,\n",
        "            'learning_rate': 0.04,\n",
        "            'num_leaves': 31,\n",
        "            'max_depth': 3,\n",
        "            'subsample': 0.8,\n",
        "            'colsample_bytree': 0.7,\n",
        "            'random_state': rnd,\n",
        "            'n_jobs': -1,\n",
        "            'verbose': -1,\n",
        "        }\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_train, y_train)\n",
        "        lgb_valid = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
        "\n",
        "        m = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_valid],\n",
        "                        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=200)])\n",
        "\n",
        "        train_pred = m.predict(X_train)\n",
        "        valid_pred = m.predict(X_test)\n",
        "        tmp_train_pred = m.predict(f_train_X)\n",
        "        test_pred_fold = m.predict(f_test_X)\n",
        "\n",
        "        train_score = log_loss(y_train,train_pred)\n",
        "        valid_score = log_loss(y_test,valid_pred)\n",
        "        print('train log loss',train_score,'valid log loss',valid_score)\n",
        "        avg_k_score += valid_score\n",
        "        rev_valid_score = 1.0/valid_score\n",
        "        reverse_score += rev_valid_score\n",
        "        print('rev',rev_valid_score)\n",
        "\n",
        "        if test_pred is None:\n",
        "            test_pred = test_pred_fold\n",
        "            weighted_test_pred = test_pred_fold * rev_valid_score\n",
        "            org_train_pred = tmp_train_pred\n",
        "            best_loss = valid_score\n",
        "            best_single_pred = test_pred_fold\n",
        "        else:\n",
        "            test_pred += test_pred_fold\n",
        "            weighted_test_pred += test_pred_fold * rev_valid_score\n",
        "            org_train_pred += tmp_train_pred\n",
        "\n",
        "            if valid_score < best_loss:\n",
        "                print('BETTER')\n",
        "                best_loss = valid_score\n",
        "                best_single_pred = test_pred_fold\n",
        "\n",
        "    test_pred = test_pred / k_cnt\n",
        "    test_pred = np.round(test_pred,4)\n",
        "    org_train_pred = org_train_pred / k_cnt\n",
        "    avg_k_score = avg_k_score/k_cnt\n",
        "\n",
        "    submiss=pd.read_csv(\"/content/drive/MyDrive/ESAA/OB/csv/sample_submission.csv\")\n",
        "    submiss['0']=test_pred[:,0]\n",
        "    submiss['1']=test_pred[:,1]\n",
        "    submiss['2']=test_pred[:,2]\n",
        "    submiss['3']=test_pred[:,3]\n",
        "    submiss['4']=test_pred[:,4]\n",
        "    submiss.to_csv(\"lgbm_{}.csv\".format(k_cnt),index=False)\n",
        "    print(reverse_score)\n",
        "    # weigthed\n",
        "    submiss=pd.read_csv(\"/content/drive/MyDrive/ESAA/OB/csv/sample_submission.csv\")\n",
        "    weighted_test_pred = weighted_test_pred / reverse_score\n",
        "    weighted_test_pred = np.round(weighted_test_pred,4)\n",
        "    submiss['0']=weighted_test_pred[:,0]\n",
        "    submiss['1']=weighted_test_pred[:,1]\n",
        "    submiss['2']=weighted_test_pred[:,2]\n",
        "    submiss['3']=weighted_test_pred[:,3]\n",
        "    submiss['4']=weighted_test_pred[:,4]\n",
        "    submiss.to_csv(\"weighted_lgbm_{}.csv\".format(k_cnt),index=False)\n",
        "    # best single\n",
        "    submiss=pd.read_csv(\"/content/drive/MyDrive/ESAA/OB/csv/sample_submission.csv\")\n",
        "    best_single_pred = np.round(best_single_pred,4)\n",
        "    submiss['0']=best_single_pred[:,0]\n",
        "    submiss['1']=best_single_pred[:,1]\n",
        "    submiss['2']=best_single_pred[:,2]\n",
        "    submiss['3']=best_single_pred[:,3]\n",
        "    submiss['4']=best_single_pred[:,4]\n",
        "    submiss.to_csv(\"single_lgbm_{}.csv\".format(k_cnt),index=False)\n",
        "\n",
        "    # train log loss\n",
        "    print('local average valid loss',avg_k_score)\n",
        "    print('train log loss', log_loss(train_Y,org_train_pred))"
      ],
      "metadata": {
        "id": "YiFem4YlLL24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_test_lgbm(5, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6LfBHhWOyVo",
        "outputId": "51eb67d2-b590-421c-a61e-c9ab7054b4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1680]\ttraining's multi_logloss: 0.305251\tvalid_1's multi_logloss: 0.51683\n",
            "train log loss 0.3052510867872835 valid log loss 0.5168300801714009\n",
            "rev 1.9348719015510112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1419]\ttraining's multi_logloss: 0.330204\tvalid_1's multi_logloss: 0.525018\n",
            "train log loss 0.3302041404046566 valid log loss 0.5250182437943189\n",
            "rev 1.9046957164249703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1287]\ttraining's multi_logloss: 0.346853\tvalid_1's multi_logloss: 0.514922\n",
            "train log loss 0.34685301360667514 valid log loss 0.5149224476552055\n",
            "rev 1.9420400189459304\n",
            "BETTER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1337]\ttraining's multi_logloss: 0.339366\tvalid_1's multi_logloss: 0.521077\n",
            "train log loss 0.3393655217235693 valid log loss 0.5210769205472182\n",
            "rev 1.9191024598629933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1760]\ttraining's multi_logloss: 0.299594\tvalid_1's multi_logloss: 0.506956\n",
            "train log loss 0.2995939159354713 valid log loss 0.50695595136555\n",
            "rev 1.9725579654531589\n",
            "BETTER\n",
            "9.673268062238064\n",
            "local average valid loss 0.5169607287067387\n",
            "train log loss 0.3457859420647463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **리더보드 결과**"
      ],
      "metadata": {
        "id": "apc1CpN1qPik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 메타 모델 : XGB 사용\n",
        "- final prediction value : weighted mean 결과가 가장 좋음\n",
        "    - public : 0.2195617319 / private : 0.2226967441\n"
      ],
      "metadata": {
        "id": "-F8Qw9ccqVsf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nIeZ3SVLwjm3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
